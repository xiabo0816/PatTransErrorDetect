<?xml version="1.0" encoding="utf-8" standalone="no"?>
<!DOCTYPE business:PatentDocumentAndRelated SYSTEM "/DTDS/ExternalStandards/ipphdb-entities.dtd"[]>
<business:PatentDocumentAndRelated xmlns:base="http://www.sipo.gov.cn/XMLSchema/base" xmlns:business="http://www.sipo.gov.cn/XMLSchema/business" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:tbl="http://oasis-open.org/specs/soextblx" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.sipo.gov.cn/XMLSchema/business /DTDS/PatentDocument/Elements/OtherElements.xsd" xsdVersion="V2.2.1" file="JP102020000022887JP00020200924470AFULJA20200611JP00X.XML" dateProduced="20200613" status="C" lang="ja" country="JP" docNumber="2020092447" kind="A" datePublication="20200611">
  <business:BibliographicData lang="ja" country="JP">
    <business:PublicationReference dataFormat="original" sequence="1" sourceDB="JP">
      <base:DocumentID>
        <base:WIPOST3Code>JP</base:WIPOST3Code>
        <base:DocNumber>2020092447</base:DocNumber>
        <base:Kind>A</base:Kind>
        <base:Date>20200611</base:Date>
      </base:DocumentID>
    </business:PublicationReference>
    <business:PublicationReference dataFormat="standard" sequence="1">
      <base:DocumentID>
        <base:WIPOST3Code>JP</base:WIPOST3Code>
        <base:DocNumber>2020092447</base:DocNumber>
        <base:Kind>A</base:Kind>
        <base:Date>20200611</base:Date>
      </base:DocumentID>
    </business:PublicationReference>
    <business:PlainLanguageDesignation lang="ja">公開特許公報(A)</business:PlainLanguageDesignation>
    <business:ApplicationReference applType="10" dataFormat="standard" sequence="1">
      <base:DocumentID>
        <base:WIPOST3Code>JP</base:WIPOST3Code>
        <base:DocNumber>102020000022887</base:DocNumber>
        <base:Date>20200213</base:Date>
      </base:DocumentID>
    </business:ApplicationReference>
    <business:ApplicationReference applType="10" dataFormat="original" sequence="1" sourceDB="JP">
      <base:DocumentID>
        <base:WIPOST3Code>JP</base:WIPOST3Code>
        <base:DocNumber>2020022887</base:DocNumber>
        <base:Date>20200213</base:Date>
      </base:DocumentID>
    </business:ApplicationReference>
    <business:ClassificationIPCRDetails>
      <business:ClassificationIPCR sequence="1">
        <business:IPCVersionDate>20060101</business:IPCVersionDate>
        <business:ClassificationLevel>A</business:ClassificationLevel>
        <business:Section>H</business:Section>
        <business:MainClass>04</business:MainClass>
        <business:Subclass>N</business:Subclass>
        <business:MainGroup>7</business:MainGroup>
        <business:Subgroup>18</business:Subgroup>
        <business:SymbolPosition>F</business:SymbolPosition>
        <business:ClassificationValue>I</business:ClassificationValue>
        <base:ActionDate>
          <base:Date>20200515</base:Date>
        </base:ActionDate>
        <business:GeneratingOffice>
          <base:WIPOST3Code>JP</base:WIPOST3Code>
        </business:GeneratingOffice>
        <business:ClassificationStatus>B</business:ClassificationStatus>
        <business:ClassificationDataSource>H</business:ClassificationDataSource>
        <base:Text>H04N   7/18        20060101AFI20200515BHJP        </base:Text>
      </business:ClassificationIPCR>
      <business:ClassificationIPCR sequence="2">
        <business:IPCVersionDate>20060101</business:IPCVersionDate>
        <business:ClassificationLevel>A</business:ClassificationLevel>
        <business:Section>E</business:Section>
        <business:MainClass>02</business:MainClass>
        <business:Subclass>F</business:Subclass>
        <business:MainGroup>9</business:MainGroup>
        <business:Subgroup>26</business:Subgroup>
        <business:SymbolPosition>L</business:SymbolPosition>
        <business:ClassificationValue>I</business:ClassificationValue>
        <base:ActionDate>
          <base:Date>20200515</base:Date>
        </base:ActionDate>
        <business:GeneratingOffice>
          <base:WIPOST3Code>JP</base:WIPOST3Code>
        </business:GeneratingOffice>
        <business:ClassificationStatus>B</business:ClassificationStatus>
        <business:ClassificationDataSource>H</business:ClassificationDataSource>
        <base:Text>E02F   9/26        20060101ALI20200515BHJP        </base:Text>
      </business:ClassificationIPCR>
      <business:ClassificationIPCR sequence="3">
        <business:IPCVersionDate>20170101</business:IPCVersionDate>
        <business:ClassificationLevel>A</business:ClassificationLevel>
        <business:Section>G</business:Section>
        <business:MainClass>06</business:MainClass>
        <business:Subclass>T</business:Subclass>
        <business:MainGroup>7</business:MainGroup>
        <business:Subgroup>00</business:Subgroup>
        <business:SymbolPosition>L</business:SymbolPosition>
        <business:ClassificationValue>I</business:ClassificationValue>
        <base:ActionDate>
          <base:Date>20200515</base:Date>
        </base:ActionDate>
        <business:GeneratingOffice>
          <base:WIPOST3Code>JP</base:WIPOST3Code>
        </business:GeneratingOffice>
        <business:ClassificationStatus>B</business:ClassificationStatus>
        <business:ClassificationDataSource>H</business:ClassificationDataSource>
        <base:Text>G06T   7/00        20170101ALI20200515BHJP        </base:Text>
      </business:ClassificationIPCR>
    </business:ClassificationIPCRDetails>
    <business:JPClassification>
      <business:FI type="main">H04N7/18 J</business:FI>
      <business:FI type="secondary">E02F9/26 B</business:FI>
      <business:FI type="secondary">G06T7/00 660B</business:FI>
      <business:FClass>
        <business:FTerm>2D015HA03</business:FTerm>
      </business:FClass>
      <business:FClass>
        <business:FTerm>2D015HB04</business:FTerm>
      </business:FClass>
      <business:FClass>
        <business:FTerm>2D015HB05</business:FTerm>
      </business:FClass>
      <business:FClass>
        <business:FTerm>5C054CA04</business:FTerm>
      </business:FClass>
      <business:FClass>
        <business:FTerm>5C054CC02</business:FTerm>
      </business:FClass>
      <business:FClass>
        <business:FTerm>5C054EA05</business:FTerm>
      </business:FClass>
      <business:FClass>
        <business:FTerm>5C054FC12</business:FTerm>
      </business:FClass>
      <business:FClass>
        <business:FTerm>5C054FD03</business:FTerm>
      </business:FClass>
      <business:FClass>
        <business:FTerm>5C054FE09</business:FTerm>
      </business:FClass>
      <business:FClass>
        <business:FTerm>5C054FE16</business:FTerm>
      </business:FClass>
      <business:FClass>
        <business:FTerm>5C054FE18</business:FTerm>
      </business:FClass>
      <business:FClass>
        <business:FTerm>5C054HA30</business:FTerm>
      </business:FClass>
      <business:FClass>
        <business:FTerm>5L096BA02</business:FTerm>
      </business:FClass>
      <business:FClass>
        <business:FTerm>5L096BA20</business:FTerm>
      </business:FClass>
      <business:FClass>
        <business:FTerm>5L096CA05</business:FTerm>
      </business:FClass>
      <business:FClass>
        <business:FTerm>5L096FA66</business:FTerm>
      </business:FClass>
      <business:FClass>
        <business:FTerm>5L096JA11</business:FTerm>
      </business:FClass>
      <business:FClass>
        <business:Theme>2D015</business:Theme>
      </business:FClass>
      <business:FClass>
        <business:Theme>5C054</business:Theme>
      </business:FClass>
      <business:FClass>
        <business:Theme>5L096</business:Theme>
      </business:FClass>
    </business:JPClassification>
    <business:InventionTitle lang="ja" dataFormat="original" sourceDB="JP">ショベル</business:InventionTitle>
    <business:RelatedDocuments>
      <business:Division>
        <business:DocumentsRelation>
          <business:ParentDocument>
            <base:DocumentID sequence="1" lang="ja">
              <base:DocNumber>2015233976</base:DocNumber>
              <base:Date>20151130</base:Date>
            </base:DocumentID>
          </business:ParentDocument>
          <business:ChildDocument>
            <base:DocumentID>
              <base:Date>00000000</base:Date>
            </base:DocumentID>
          </business:ChildDocument>
        </business:DocumentsRelation>
      </business:Division>
    </business:RelatedDocuments>
    <business:Parties>
      <business:ApplicantDetails>
        <business:Applicant sequence="1" dataFormat="original" sourceDB="JP">
          <base:AddressBook lang="ja">
            <base:Name>住友重機械工業株式会社</base:Name>
            <base:RegisteredNumber>000002107</base:RegisteredNumber>
            <base:Address>
              <base:AddressLine>0</base:AddressLine>
              <base:AddressMailCode>0</base:AddressMailCode>
              <base:PostBox>0</base:PostBox>
              <base:AddressRoom>0</base:AddressRoom>
              <base:AddressFloor>0</base:AddressFloor>
              <base:AddressBuilding>0</base:AddressBuilding>
              <base:Street>0</base:Street>
              <base:AddressCity>0</base:AddressCity>
              <base:County>0</base:County>
              <base:City>0</base:City>
              <base:Province>0</base:Province>
              <base:PostCode>0</base:PostCode>
              <base:WIPOST3Code>JP</base:WIPOST3Code>
              <base:Text>東京都品川区大崎二丁目１番１号</base:Text>
            </base:Address>
          </base:AddressBook>
          <business:OrganizationCode createDate="00000000" creator="00">0000000000</business:OrganizationCode>
        </business:Applicant>
      </business:ApplicantDetails>
      <business:InventorDetails>
        <business:Inventor sequence="1" dataFormat="original" sourceDB="JP">
          <base:AddressBook lang="ja">
            <base:Name>清田  芳永</base:Name>
            <base:Address>
              <base:AddressLine>0</base:AddressLine>
              <base:AddressMailCode>0</base:AddressMailCode>
              <base:PostBox>0</base:PostBox>
              <base:AddressRoom>0</base:AddressRoom>
              <base:AddressFloor>0</base:AddressFloor>
              <base:AddressBuilding>0</base:AddressBuilding>
              <base:Street>0</base:Street>
              <base:AddressCity>0</base:AddressCity>
              <base:County>0</base:County>
              <base:City>0</base:City>
              <base:Province>0</base:Province>
              <base:PostCode>0</base:PostCode>
              <base:WIPOST3Code>JP</base:WIPOST3Code>
              <base:Text>神奈川県横須賀市夏島町１９番地  住友重機械工業株式会社  横須賀製造所内</base:Text>
            </base:Address>
          </base:AddressBook>
        </business:Inventor>
        <business:Inventor sequence="2" dataFormat="original" sourceDB="JP">
          <base:AddressBook lang="ja">
            <base:Name>大槻  俊介</base:Name>
            <base:Address>
              <base:AddressLine>0</base:AddressLine>
              <base:AddressMailCode>0</base:AddressMailCode>
              <base:PostBox>0</base:PostBox>
              <base:AddressRoom>0</base:AddressRoom>
              <base:AddressFloor>0</base:AddressFloor>
              <base:AddressBuilding>0</base:AddressBuilding>
              <base:Street>0</base:Street>
              <base:AddressCity>0</base:AddressCity>
              <base:County>0</base:County>
              <base:City>0</base:City>
              <base:Province>0</base:Province>
              <base:PostCode>0</base:PostCode>
              <base:WIPOST3Code>JP</base:WIPOST3Code>
              <base:Text>神奈川県横須賀市夏島町１９番地  住友重機械工業株式会社  横須賀製造所内</base:Text>
            </base:Address>
          </base:AddressBook>
        </business:Inventor>
        <business:Inventor sequence="3" dataFormat="original" sourceDB="JP">
          <base:AddressBook lang="ja">
            <base:Name>相澤  晋</base:Name>
            <base:Address>
              <base:AddressLine>0</base:AddressLine>
              <base:AddressMailCode>0</base:AddressMailCode>
              <base:PostBox>0</base:PostBox>
              <base:AddressRoom>0</base:AddressRoom>
              <base:AddressFloor>0</base:AddressFloor>
              <base:AddressBuilding>0</base:AddressBuilding>
              <base:Street>0</base:Street>
              <base:AddressCity>0</base:AddressCity>
              <base:County>0</base:County>
              <base:City>0</base:City>
              <base:Province>0</base:Province>
              <base:PostCode>0</base:PostCode>
              <base:WIPOST3Code>JP</base:WIPOST3Code>
              <base:Text>神奈川県横須賀市夏島町１９番地  住友重機械工業株式会社  横須賀製造所内</base:Text>
            </base:Address>
          </base:AddressBook>
        </business:Inventor>
      </business:InventorDetails>
      <business:AgentDetails>
        <business:CustomerNumber>00000</business:CustomerNumber>
        <business:Agent sequence="1" dataFormat="original" sourceDB="JP" repType="agent">
          <base:AddressBook lang="ja">
            <base:Name>伊東  忠重</base:Name>
            <base:RegisteredNumber>100107766</base:RegisteredNumber>
          </base:AddressBook>
        </business:Agent>
        <business:Agent sequence="2" dataFormat="original" sourceDB="JP" repType="agent">
          <base:AddressBook lang="ja">
            <base:Name>伊東  忠彦</base:Name>
            <base:RegisteredNumber>100070150</base:RegisteredNumber>
          </base:AddressBook>
        </business:Agent>
      </business:AgentDetails>
    </business:Parties>
    <business:SpecificBibliographicData>
      <business:OriginalKindCode>A</business:OriginalKindCode>
    </business:SpecificBibliographicData>
    <business:StatisticalInformation>
      <business:ClaimsCount>10</business:ClaimsCount>
      <base:TotalPageCount>29</base:TotalPageCount>
    </business:StatisticalInformation>
  </business:BibliographicData>
  <business:Abstract dataFormat="original" lang="ja" sourceDB="JP">
    <base:Paragraphs>【課題】作業機械によって検知された人が表示画像内のどの領域に存在するのかを操作者に容易に認識させることができる作業機械用周辺監視システムを提供すること。
【解決手段】周辺監視システム１００は、ショベル周辺に存在する人を検知する人検知部３４と、ショベルに搭載された出力装置５０を制御する制御部３５と、を備える。制御部３５は、ショベルに取り付けられる撮像装置４０の撮像画像を用いて生成される出力画像をディスプレイに表示し、人検知部３４がショベル周辺に存在する人を検知した場合に警報を出力し、且つ、人検知部３４が検知した人に対応する出力画像上の画像部分を区別可能に表示する。
【選択図】図２</base:Paragraphs>
    <business:AbstractFigure>
      <base:Figure num="0001">
        <base:Image id="000002" he="49" wi="69" file="2020092447_000002.TIF" imgFormat="TIFF" imgContent="drawing" />
      </base:Figure>
    </business:AbstractFigure>
  </business:Abstract>
  <business:Description dataFormat="original" sourceDB="JP">
    <business:TechnicalField>
      <base:Paragraphs num="0001">
  本発明は、作業機械の周囲を監視する作業機械用周辺監視システムに関する。
</base:Paragraphs>
    </business:TechnicalField>
    <business:BackgroundArt>
      <base:Paragraphs num="0002">
  ショベル周辺に存在する物体（人）を検知するセンサを備えたショベルが知られている（特許文献１参照。）。このショベルは、ショベルの右側で物体（人）を検知した場合に運転室内の右壁に設置されたスピーカから警報を出力させ、且つ、ショベルの右側を撮像するカメラのスルー画像をディスプレイに表示させる。また、ショベルの左側で物体（人）を検知した場合に運転室内の左壁に設置されたスピーカから警報を出力させ、且つ、ショベルの左側を撮像するカメラのスルー画像をディスプレイに表示させる。
</base:Paragraphs>
    </business:BackgroundArt>
    <business:CitationList>
      <business:PatentDocumentation>
        <base:Paragraphs num="0003">
          <business:ApplicationCitation num="0001">
            <base:Text>特開２０１４－１８３５００号公報</base:Text>
          </business:ApplicationCitation>
        </base:Paragraphs>
      </business:PatentDocumentation>
    </business:CitationList>
    <business:InventionSummary>
      <business:TechnicalProblem>
        <base:Paragraphs num="0004">
  しかしながら、上述のショベルは、センサが検知した物体（人）と、ディスプレイに表示された画像内の物体（人）とを対応付けていない。そのため、ディスプレイを見た操作者は、センサが検知した物体（人）が画像内の何れの物体（人）であるかを認識できないおそれがある。
</base:Paragraphs>
        <base:Paragraphs num="0005">
  上述に鑑み、作業機械によって検知された人が表示画像内のどの領域に存在するのかを操作者に容易に認識させることができる作業機械用周辺監視システムの提供が望まれる。
</base:Paragraphs>
      </business:TechnicalProblem>
      <business:TechnicalSolution>
        <base:Paragraphs num="0006">
  本発明の実施例に係る作業機械用周辺監視システムは、前記作業機械の周辺に存在する人を検知する人検知部と、前記作業機械に搭載された出力装置を制御する制御部と、を備え、前記制御部は、前記作業機械に取り付けられる撮像装置の撮像画像を用いて生成される出力画像をディスプレイに表示し、前記人検知部が前記作業機械の周辺に存在する人を検知した場合に警報を出力し、且つ、前記人検知部が検知した人に対応する前記出力画像上の画像部分を区別可能に表示する。
</base:Paragraphs>
      </business:TechnicalSolution>
      <business:AdvantageousEffects>
        <base:Paragraphs num="0007">
  上述の手段により、作業機械によって検知された人が表示画像内のどの領域に存在するのかを操作者に容易に認識させることができる作業機械用周辺監視システムが提供される。
</base:Paragraphs>
      </business:AdvantageousEffects>
    </business:InventionSummary>
    <business:DrawingsDescription>
      <base:Paragraphs num="0008">
        <base:FigureReference num="0001">本発明の実施例に係る周辺監視システムが搭載されるショベルの側面図である。</base:FigureReference>
        <base:FigureReference num="0002">周辺監視システムの構成例を示す機能ブロック図である。</base:FigureReference>
        <base:FigureReference num="0003">後方カメラの撮像画像の例である。</base:FigureReference>
        <base:FigureReference num="0004">撮像画像から識別処理対象画像を切り出す際に用いられる幾何学的関係の一例を示す概略図である。</base:FigureReference>
        <base:FigureReference num="0005">ショベル後方の実空間の上面視である。</base:FigureReference>
        <base:FigureReference num="0006">撮像画像から正規化画像を生成する処理の流れを示す図である。</base:FigureReference>
        <base:FigureReference num="0007">撮像画像と識別処理対象画像領域と正規化画像との関係を示す図である。</base:FigureReference>
        <base:FigureReference num="0008">識別処理対象画像領域と識別処理不適領域との関係を示す図である。</base:FigureReference>
        <base:FigureReference num="0009">正規化画像の例を示す図である。</base:FigureReference>
        <base:FigureReference num="0010">撮像画像から識別処理対象画像を切り出す際に用いられる幾何学的関係の別の一例を示す概略図である。</base:FigureReference>
        <base:FigureReference num="0011">撮像画像における特徴画像の一例を示す図である。</base:FigureReference>
        <base:FigureReference num="0012">画像抽出処理の一例の流れを示すフローチャートである。</base:FigureReference>
        <base:FigureReference num="0013">周辺監視処理の一例の流れを示すフローチャートである。</base:FigureReference>
        <base:FigureReference num="0014">制限解除処理の一例の流れを示すフローチャートである。</base:FigureReference>
        <base:FigureReference num="0015">出力画像の例を示す図である。</base:FigureReference>
        <base:FigureReference num="0016">検知状態と枠及び領域の表示色との対応関係を示す対応テーブルである。</base:FigureReference>
        <base:FigureReference num="0017">出力画像としての視点変換画像の例である。</base:FigureReference>
        <base:FigureReference num="0018">視点変換画像を含む出力画像の例である。</base:FigureReference>
      </base:Paragraphs>
    </business:DrawingsDescription>
    <business:EmbodimentsDescription>
      <base:Paragraphs num="0009">
  図１は、本発明の実施例に係る周辺監視システム１００が搭載される建設機械としてのショベルの側面図である。ショベルの下部走行体１には、旋回機構２を介して上部旋回体３が搭載される。上部旋回体３には、ブーム４が取り付けられる。ブーム４の先端にはアーム５が取り付けられ、アーム５の先端にはバケット６が取り付けられる。ブーム４、アーム５、及びバケット６は掘削アタッチメントを構成し、ブームシリンダ７、アームシリンダ８、及びバケットシリンダ９によりそれぞれ油圧駆動される。また、上部旋回体３には、キャビン１０が設けられ、且つエンジン等の動力源が搭載される。また、上部旋回体３の上部には撮像装置４０が取り付けられる。具体的には、上部旋回体３の後端上部、左端上部、右端上部に後方カメラ４０Ｂ、左側方カメラ４０Ｌ、右側方カメラ４０Ｒが取り付けられる。また、キャビン１０内にはコントローラ３０及び出力装置５０が設置される。
</base:Paragraphs>
      <base:Paragraphs num="0010">
  図２は、周辺監視システム１００の構成例を示す機能ブロック図である。周辺監視システム１００は、主に、コントローラ３０、撮像装置４０、及び出力装置５０を含む。
</base:Paragraphs>
      <base:Paragraphs num="0011">
  コントローラ３０は、ショベルの駆動制御を行う制御装置である。本実施例では、コントローラ３０は、ＣＰＵ及び内部メモリを含む演算処理装置で構成され、内部メモリに格納された駆動制御用のプログラムをＣＰＵに実行させて各種機能を実現する。
</base:Paragraphs>
      <base:Paragraphs num="0012">
  また、コントローラ３０は、各種装置の出力に基づいてショベルの周辺に人が存在するかを判定し、その判定結果に応じて各種装置を制御する。具体的には、コントローラ３０は、撮像装置４０及び入力装置４１の出力を受け、抽出部３１、識別部３２、追跡部３３、及び制御部３５のそれぞれに対応するソフトウェアプログラムを実行する。そして、その実行結果に応じて機械制御装置５１に制御指令を出力してショベルの駆動制御を実行し、或いは、出力装置５０から各種情報を出力させる。なお、コントローラ３０は、画像処理専用の制御装置であってもよい。
</base:Paragraphs>
      <base:Paragraphs num="0013">
  撮像装置４０は、ショベルの周囲の画像を撮像する装置であり、撮像した画像をコントローラ３０に対して出力する。本実施例では、撮像装置４０は、ＣＣＤ等の撮像素子を採用するワイドカメラであり、上部旋回体３の上部において光軸が斜め下方を向くように取り付けられる。
</base:Paragraphs>
      <base:Paragraphs num="0014">
  入力装置４１は操作者の入力を受ける装置である。本実施例では、入力装置４１は、操作装置（操作レバー、操作ペダル等）、ゲートロックレバー、操作装置の先端に設置されたボタン、車載ディスプレイに付属のボタン、タッチパネル等を含む。
</base:Paragraphs>
      <base:Paragraphs num="0015">
  出力装置５０は、各種情報を出力する装置であり、例えば、各種画像情報を表示する車載ディスプレイ、各種音声情報を音声出力する車載スピーカ、警報ブザー、警報ランプ等を含む。本実施例では、出力装置５０は、コントローラ３０からの制御指令に応じて各種情報を出力する。
</base:Paragraphs>
      <base:Paragraphs num="0016">
  機械制御装置５１は、ショベルの動きを制御する装置であり、例えば、油圧システムにおける作動油の流れを制御する制御弁、ゲートロック弁、エンジン制御装置等を含む。
</base:Paragraphs>
      <base:Paragraphs num="0017">
  抽出部３１は、撮像装置４０が撮像した撮像画像から識別処理対象画像を抽出する機能要素である。具体的には、抽出部３１は、局所的な輝度勾配又はエッジに基づく簡易な特徴、Hough変換等による幾何学的特徴、輝度に基づいて分割された領域の面積又はアスペクト比に関する特徴等を抽出する比較的演算量の少ない画像処理（以下、「前段画像認識処理」とする。）によって識別処理対象画像を抽出する。識別処理対象画像は、後続の画像処理の対象となる画像部分（撮像画像の一部）であり、人候補画像を含む。人候補画像は、人画像である可能性が高いとされる画像部分（撮像画像の一部）である。
</base:Paragraphs>
      <base:Paragraphs num="0018">
  識別部３２は、抽出部３１が抽出した識別処理対象画像に含まれる人候補画像が人画像であるかを識別する機能要素である。具体的には、識別部３２は、ＨＯＧ（Histograms of Oriented Gradients）特徴量に代表される画像特徴量記述と機械学習により生成した識別器とを用いた画像認識処理等の比較的演算量の多い画像処理（以下、「後段画像認識処理」とする。）によって人候補画像が人画像であるかを識別する。識別部３２が人候補画像を人画像として識別する割合は、抽出部３１による識別処理対象画像の抽出が高精度であるほど高くなる。なお、識別部３２は、夜間、悪天候時等の撮像に適さない環境下で所望の品質の撮像画像を得られない場合等においては、人候補画像の全てが人画像であると識別し、抽出部３１が抽出した識別処理対象画像における人候補画像の全てを人であると識別してもよい。人の検知漏れを防止するためである。
</base:Paragraphs>
      <base:Paragraphs num="0019">
  次に、図３を参照し、後方カメラ４０Ｂが撮像したショベル後方の撮像画像における人画像の見え方について説明する。なお、図３の２つの撮像画像は、後方カメラ４０Ｂの撮像画像の例である。また、図３の点線円は人画像の存在を表し、実際の撮像画像には表示されない。
</base:Paragraphs>
      <base:Paragraphs num="0020">
  後方カメラ４０Ｂは、ワイドカメラであり、且つ、人を斜め上から見下ろす高さに取り付けられる。そのため、撮像画像における人画像の見え方は、後方カメラ４０Ｂから見た人の存在方向によって大きく異なる。例えば、撮像画像中の人画像は、撮像画像の左右の端部に近いほど傾いて表示される。これは、ワイドカメラの広角レンズに起因する像倒れによる。また、後方カメラ４０Ｂに近いほど頭部が大きく表示される。また、脚部がショベルの車体の死角に入って見えなくなってしまう。これらは、後方カメラ４０Ｂの設置位置に起因する。そのため、撮像画像に何らの加工を施すことなく画像処理によってその撮像画像に含まれる人画像を識別するのは困難である。
</base:Paragraphs>
      <base:Paragraphs num="0021">
  そこで、本発明の実施例に係る周辺監視システム１００は、識別処理対象画像を正規化することで、識別処理対象画像に含まれる人画像の識別を促進する。なお、「正規化」は、識別処理対象画像を所定サイズ及び所定形状の画像に変換することを意味する。本実施例では、撮像画像において様々な形状を取り得る識別処理対象画像は射影変換によって所定サイズの長方形画像に変換される。なお、射影変換としては例えば８変数の射影変換行列が用いられる。
</base:Paragraphs>
      <base:Paragraphs num="0022">
  ここで、図４～図６を参照し、周辺監視システム１００が識別処理対象画像を正規化する処理（以下、「正規化処理」とする。）の一例について説明する。なお、図４は、抽出部３１が撮像画像から識別処理対象画像を切り出す際に用いる幾何学的関係の一例を示す概略図である。
</base:Paragraphs>
      <base:Paragraphs num="0023">
  図４のボックスＢＸは、実空間における仮想立体物であり、本実施例では、８つの頂点Ａ～Ｈで定められる仮想直方体である。また、点Ｐｒは、識別処理対象画像を参照するために予め設定される参照点である。本実施例では、参照点Ｐｒは、人の想定立ち位置として予め設定される点であり、４つの頂点Ａ～Ｄで定められる四角形ＡＢＣＤの中心に位置する。また、ボックスＢＸのサイズは、人の向き、歩幅、身長等に基づいて設定される。本実施例では、四角形ＡＢＣＤ及び四角形ＥＦＧＨは正方形であり、一辺の長さは例えば８００ｍｍである。また、直方体の高さは例えば１８００ｍｍである。すなわち、ボックスＢＸは、幅８００ｍｍ×奥行８００ｍｍ×高さ１８００ｍｍの直方体である。
</base:Paragraphs>
      <base:Paragraphs num="0024">
  ４つの頂点Ａ、Ｂ、Ｇ、Ｈで定められる四角形ＡＢＧＨは、撮像画像における識別処理対象画像の領域に対応する仮想平面領域ＴＲを形成する。また、仮想平面領域ＴＲとしての四角形ＡＢＧＨは、水平面である仮想地面に対して傾斜する。
</base:Paragraphs>
      <base:Paragraphs num="0025">
  なお、本実施例では、参照点Ｐｒと仮想平面領域ＴＲとの関係を定めるために仮想直方体としてのボックスＢＸが採用される。しかしながら、撮像装置４０の方向を向き且つ仮想地面に対して傾斜する仮想平面領域ＴＲを任意の参照点Ｐｒに関連付けて定めることができるのであれば、他の仮想立体物を用いた関係等の他の幾何学的関係が採用されてもよく、関数、変換テーブル等の他の数学的関係が採用されてもよい。
</base:Paragraphs>
      <base:Paragraphs num="0026">
  図５は、ショベル後方の実空間の上面視であり、参照点Ｐｒ１、Ｐｒ２を用いて仮想平面領域ＴＲ１、ＴＲ２が参照された場合における後方カメラ４０Ｂと仮想平面領域ＴＲ１、ＴＲ２との位置関係を示す。なお、本実施例では、参照点Ｐｒは、仮想地面上の仮想グリッドの格子点のそれぞれに配置可能である。但し、参照点Ｐｒは、仮想地面上に不規則に配置されてもよく、後方カメラ４０Ｂの仮想地面への投影点から放射状に伸びる線分上に等間隔に配置されてもよい。例えば、各線分は１度刻みで放射状に伸び、参照点Ｐｒは各線分上に１００ｍｍ間隔に配置される。
</base:Paragraphs>
      <base:Paragraphs num="0027">
  図４及び図５に示すように、四角形ＡＢＦＥ（図４参照。）で定められるボックスＢＸの第１面は、参照点Ｐｒ１を用いて仮想平面領域ＴＲ１が参照される場合、後方カメラ４０Ｂに正対するように配置される。すなわち、後方カメラ４０Ｂと参照点Ｐｒ１とを結ぶ線分は、参照点Ｐｒ１に関連して配置されるボックスＢＸの第１面と上面視で直交する。同様に、ボックスＢＸの第１面は、参照点Ｐｒ２を用いて仮想平面領域ＴＲ２が参照される場合にも、後方カメラ４０Ｂに正対するように配置される。すなわち、後方カメラ４０Ｂと参照点Ｐｒ２とを結ぶ線分は、参照点Ｐｒ２に関連して配置されるボックスＢＸの第１面と上面視で直交する。この関係は、参照点Ｐｒが何れの格子点上に配置された場合であっても成立する。すなわち、ボックスＢＸは、その第１面が常に後方カメラ４０Ｂに正対するように配置される。
</base:Paragraphs>
      <base:Paragraphs num="0028">
  図６は、撮像画像から正規化画像を生成する処理の流れを示す図である。具体的には、図６（Ａ）は、後方カメラ４０Ｂの撮像画像の一例であり、実空間における参照点Ｐｒに関連して配置されるボックスＢＸを映し出す。また、図６（Ｂ）は、撮像画像における識別処理対象画像の領域（以下、「識別処理対象画像領域ＴＲｇ」とする。）を切り出した図であり、図６（Ａ）の撮像画像に映し出された仮想平面領域ＴＲに対応する。また、図６（Ｃ）は、識別処理対象画像領域ＴＲｇを有する識別処理対象画像を正規化した正規化画像ＴＲｇｔを示す。
</base:Paragraphs>
      <base:Paragraphs num="0029">
  図６（Ａ）に示すように、実空間上で参照点Ｐｒ１に関連して配置されるボックスＢＸは、実空間における仮想平面領域ＴＲの位置を定め、そして、仮想平面領域ＴＲに対応する撮像画像上の識別処理対象画像領域ＴＲｇを定める。
</base:Paragraphs>
      <base:Paragraphs num="0030">
  このように、実空間における参照点Ｐｒの位置が決まれば、実空間における仮想平面領域ＴＲの位置が一意に決まり、撮像画像における識別処理対象画像領域ＴＲｇも一意に決まる。そして、抽出部３１は、識別処理対象画像領域ＴＲｇを有する識別処理対象画像を正規化して所定サイズの正規化画像ＴＲｇｔを生成できる。本実施例では、正規化画像ＴＲｇｔのサイズは、例えば縦６４ピクセル×横３２ピクセルである。
</base:Paragraphs>
      <base:Paragraphs num="0031">
  図７は、撮像画像と識別処理対象画像領域と正規化画像との関係を示す図である。具体的には、図７（Ａ１）は、撮像画像における識別処理対象画像領域ＴＲｇ３を示し、図７（Ａ２）は、識別処理対象画像領域ＴＲｇ３を有する識別処理対象画像の正規化画像ＴＲｇｔ３を示す。また、図７（Ｂ１）は、撮像画像における識別処理対象画像領域ＴＲｇ４を示し、図７（Ｂ２）は、識別処理対象画像領域ＴＲｇ４を有する識別処理対象画像の正規化画像ＴＲｇｔ４を示す。同様に、図７（Ｃ１）は、撮像画像における識別処理対象画像領域ＴＲｇ５を示し、図７（Ｃ２）は、識別処理対象画像領域ＴＲｇ５を有する識別処理対象画像の正規化画像ＴＲｇｔ５を示す。
</base:Paragraphs>
      <base:Paragraphs num="0032">
  図７に示すように、撮像画像における識別処理対象画像領域ＴＲｇ５は、撮像画像における識別処理対象画像領域ＴＲｇ４より大きい。識別処理対象画像領域ＴＲｇ５に対応する仮想平面領域と後方カメラ４０Ｂとの間の距離が、識別処理対象画像領域ＴＲｇ４に対応する仮想平面領域と後方カメラ４０Ｂとの間の距離より小さいためである。同様に、撮像画像における識別処理対象画像領域ＴＲｇ４は、撮像画像における識別処理対象画像領域ＴＲｇ３より大きい。識別処理対象画像領域ＴＲｇ４に対応する仮想平面領域と後方カメラ４０Ｂとの間の距離が、識別処理対象画像領域ＴＲｇ３に対応する仮想平面領域と後方カメラ４０Ｂとの間の距離より小さいためである。すなわち、撮像画像における識別処理対象画像領域は、対応する仮想平面領域と後方カメラ４０Ｂとの間の距離が大きいほど小さい。その一方で、正規化画像ＴＲｇｔ３、ＴＲｇｔ４、ＴＲｇｔ５は何れも同じサイズの長方形画像である。
</base:Paragraphs>
      <base:Paragraphs num="0033">
  このように、抽出部３１は、撮像画像において様々な形状及びサイズを取り得る識別処理対象画像を所定サイズの長方形画像に正規化し、人画像を含む人候補画像を正規化できる。具体的には、抽出部３１は、正規化画像の所定領域に人候補画像の頭部であると推定される画像部分（以下、「頭部画像部分」とする。）を配置する。また、正規化画像の別の所定領域に人候補画像の胴体部であると推定される画像部分（以下、「胴体部画像部分」とする。）を配置し、正規化画像のさらに別の所定領域に人候補画像の脚部であると推定される画像部分（以下、「脚部画像部分」とする。）を配置する。また、抽出部３１は、正規化画像の形状に対する人候補画像の傾斜（像倒れ）を抑えた状態で正規化画像を取得できる。
</base:Paragraphs>
      <base:Paragraphs num="0034">
  次に、図８を参照し、識別処理対象画像領域が、人画像の識別に悪影響を与える識別に適さない画像領域（以下、「識別処理不適領域」とする。）を含む場合の正規化処理について説明する。識別処理不適領域は、人画像が存在し得ない既知の領域であり、例えば、ショベルの車体が映り込んだ領域（以下、「車体映り込み領域」とする。）、撮像画像からはみ出た領域（以下、「はみ出し領域」とする。）等を含む。なお、図８は、識別処理対象画像領域と識別処理不適領域との関係を示す図であり、図７（Ｃ１）及び図７（Ｃ２）に対応する。また、図８左図の右下がりの斜線ハッチング領域は、はみ出し領域Ｒ１に対応し、左下がりの斜線ハッチング領域は、車体映り込み領域Ｒ２に対応する。
</base:Paragraphs>
      <base:Paragraphs num="0035">
  本実施例では、抽出部３１は、識別処理対象画像領域ＴＲｇ５がはみ出し領域Ｒ１及び車体映り込み領域Ｒ２の一部を含む場合、それらの識別処理不適領域をマスク処理した後で、識別処理対象画像領域ＴＲｇ５を有する識別処理対象画像の正規化画像ＴＲｇｔ５を生成する。なお、抽出部３１は、正規化画像ＴＲｇｔ５を生成した後で、正規化画像ＴＲｇｔ５における識別処理不適領域に対応する部分をマスク処理してもよい。
</base:Paragraphs>
      <base:Paragraphs num="0036">
  図８右図は、正規化画像ＴＲｇｔ５を示す。また、図８右図において、右下がりの斜線ハッチング領域は、はみ出し領域Ｒ１に対応するマスク領域Ｍ１を表し、左下がりの斜線ハッチング領域は、車体映り込み領域Ｒ２の一部に対応するマスク領域Ｍ２を表す。
</base:Paragraphs>
      <base:Paragraphs num="0037">
  このようにして、抽出部３１は、識別処理不適領域の画像をマスク処理することで、識別処理不適領域の画像が識別部３２による識別処理に影響を及ぼすのを防止する。このマスク処理により、識別部３２は、識別処理不適領域の画像の影響を受けることなく、正規化画像におけるマスク領域以外の領域の画像を用いて人画像であるかを識別できる。なお、抽出部３１は、マスク処理以外の他の任意の公知方法で、識別処理不適領域の画像が識別部３２による識別処理に影響を及ぼさないようにしてもよい。
</base:Paragraphs>
      <base:Paragraphs num="0038">
  次に、図９を参照し、抽出部３１が生成する正規化画像の特徴について説明する。なお、図９は、正規化画像の例を示す図である。また、図９に示す１４枚の正規化画像は、図の左端に近い正規化画像ほど、後方カメラ４０Ｂから近い位置に存在する人候補の画像を含み、図の右端に近い正規化画像ほど、後方カメラ４０Ｂから遠い位置に存在する人候補の画像を含む。
</base:Paragraphs>
      <base:Paragraphs num="0039">
  図９に示すように、抽出部３１は、実空間における仮想平面領域ＴＲと後方カメラ４０Ｂとの間の後方水平距離（図５に示すＹ軸方向の水平距離）に関係なく、何れの正規化画像内においてもほぼ同じ割合で頭部画像部分、胴体部画像部分、脚部画像部分等を配置できる。そのため、抽出部３１は、識別部３２が識別処理を実行する際の演算負荷を低減でき、且つ、その識別結果の信頼性を向上できる。なお、上述の後方水平距離は、実空間における仮想平面領域ＴＲと後方カメラ４０Ｂとの間の位置関係に関する情報の一例であり、抽出部３１は、抽出した識別処理対象画像にその情報を付加する。また、上述の位置関係に関する情報は、仮想平面領域ＴＲに対応する参照点Ｐｒと後方カメラ４０Ｂとを結ぶ線分の後方カメラ４０Ｂの光軸に対する上面視角度等を含む。
</base:Paragraphs>
      <base:Paragraphs num="0040">
  以上の構成により、周辺監視システム１００は、撮像装置４０の方向を向き且つ水平面である仮想地面に対して傾斜する仮想平面領域ＴＲに対応する識別処理対象画像領域ＴＲｇから正規化画像ＴＲｇｔを生成する。そのため、人の高さ方向及び奥行き方向の見え方を考慮した正規化を実現できる。その結果、人を斜め上から撮像するように建設機械に取り付けられる撮像装置４０の撮像画像を用いた場合であっても建設機械の周囲に存在する人をより確実に検知できる。特に、人が撮像装置４０に接近した場合であっても、撮像画像上の十分な大きさの領域を占める識別処理対象画像から正規化画像を生成できるため、その人を確実に検知できる。
</base:Paragraphs>
      <base:Paragraphs num="0041">
  また、周辺監視システム１００は、実空間における仮想直方体であるボックスＢＸの４つの頂点Ａ、Ｂ、Ｇ、Ｈで形成される矩形領域として仮想平面領域ＴＲを定義する。そのため、実空間における参照点Ｐｒと仮想平面領域ＴＲとを幾何学的に対応付けることができ、さらには、実空間における仮想平面領域ＴＲと撮像画像における識別処理対象画像領域ＴＲｇとを幾何学的に対応付けることができる。
</base:Paragraphs>
      <base:Paragraphs num="0042">
  また、抽出部３１は、識別処理対象画像領域ＴＲｇに含まれる識別処理不適領域の画像をマスク処理する。そのため、識別部３２は、車体映り込み領域Ｒ２を含む識別処理不適領域の画像の影響を受けることなく、正規化画像におけるマスク領域以外の領域の画像を用いて人画像であるかを識別できる。
</base:Paragraphs>
      <base:Paragraphs num="0043">
  また、抽出部３１は、参照点Ｐｒ毎に識別処理対象画像を抽出可能である。また、識別処理対象画像領域ＴＲｇのそれぞれは、対応する仮想平面領域ＴＲを介して、人の想定立ち位置として予め設定される参照点Ｐｒの１つに関連付けられる。そのため、周辺監視システム１００は、人が存在する可能性が高い参照点Ｐｒを任意の方法で抽出することで、人候補画像を含む可能性が高い識別処理対象画像を抽出できる。この場合、人候補画像を含む可能性が低い識別処理対象画像に対して、比較的演算量の多い画像処理による識別処理が施されてしまうのを防止でき、人検知処理の高速化を実現できる。
</base:Paragraphs>
      <base:Paragraphs num="0044">
  次に、図１０及び図１１を参照し、人候補画像を含む可能性が高い識別処理対象画像を抽出部３１が抽出する処理の一例について説明する。なお、図１０は、抽出部３１が撮像画像から識別処理対象画像を切り出す際に用いる幾何学的関係の一例を示す概略図であり、図４に対応する。また、図１１は、撮像画像における特徴画像の一例を示す図である。なお、特徴画像は、人の特徴的な部分を表す画像であり、望ましくは、実空間における地面からの高さが変化し難い部分を表す画像である。そのため、特徴画像は、例えば、ヘルメットの画像、肩の画像、頭の画像、人に取り付けられる反射板若しくはマーカの画像等を含む。
</base:Paragraphs>
      <base:Paragraphs num="0045">
  特に、ヘルメットは、その形状がおよそ球体であり、その投影像が撮像画像上に投影されたときに撮像方向によらず常に円形に近いという特徴を有する。また、ヘルメットは、表面が硬質で光沢又は半光沢を有し、その投影像が撮像画像上に投影されたときに局所的な高輝度領域とその領域を中心とする放射状の輝度勾配を生じさせ易いという特徴を有する。そのため、ヘルメットの画像は、特徴画像として特に相応しい。なお、その投影像が円形に近いという特徴、局所的な高輝度領域を中心とする放射状の輝度勾配を生じさせ易いという特徴等は、撮像画像からヘルメットの画像を見つけ出す画像処理のために利用されてもよい。また、撮像画像からヘルメットの画像を見つけ出す画像処理は、例えば、輝度平滑化処理、ガウス平滑化処理、輝度極大点探索処理、輝度極小点探索処理等を含む。
</base:Paragraphs>
      <base:Paragraphs num="0046">
  本実施例では、抽出部３１は、前段画像認識処理によって、撮像画像におけるヘルメット画像（厳密にはヘルメットであると推定できる画像）を見つけ出す。ショベルの周囲で作業する人はヘルメットを着用していると考えられるためである。そして、抽出部３１は、見つけ出したヘルメット画像の位置から最も関連性の高い参照点Ｐｒを導き出す。その上で、抽出部３１は、その参照点Ｐｒに対応する識別処理対象画像を抽出する。
</base:Paragraphs>
      <base:Paragraphs num="0047">
  具体的には、抽出部３１は、図１０に示す幾何学的関係を利用し、撮像画像におけるヘルメット画像の位置から関連性の高い参照点Ｐｒを導き出す。なお、図１０の幾何学的関係は、実空間における仮想頭部位置ＨＰを定める点で図４の幾何学的関係と相違するが、その他の点で共通する。
</base:Paragraphs>
      <base:Paragraphs num="0048">
  仮想頭部位置ＨＰは、参照点Ｐｒ上に存在すると想定される人の頭部位置を表し、参照点Ｐｒの真上に配置される。本実施例では、参照点Ｐｒ上の高さ１７００ｍｍのところに配置される。そのため、実空間における仮想頭部位置ＨＰが決まれば、実空間における参照点Ｐｒの位置が一意に決まり、実空間における仮想平面領域ＴＲの位置も一意に決まる。また、撮像画像における識別処理対象画像領域ＴＲｇも一意に決まる。そして、抽出部３１は、識別処理対象画像領域ＴＲｇを有する識別処理対象画像を正規化して所定サイズの正規化画像ＴＲｇｔを生成できる。
</base:Paragraphs>
      <base:Paragraphs num="0049">
  逆に、実空間における参照点Ｐｒの位置が決まれば、実空間における仮想頭部位置ＨＰが一意に決まり、実空間における仮想頭部位置ＨＰに対応する撮像画像上の頭部画像位置ＡＰも一意に決まる。そのため、頭部画像位置ＡＰは、予め設定されている参照点Ｐｒのそれぞれに対応付けて予め設定され得る。なお、頭部画像位置ＡＰは、参照点Ｐｒからリアルタイムに導き出されてもよい。
</base:Paragraphs>
      <base:Paragraphs num="0050">
  そこで、抽出部３１は、前段画像認識処理により後方カメラ４０Ｂの撮像画像内でヘルメット画像を探索する。図１１上図は、抽出部３１がヘルメット画像ＨＲｇを見つけ出した状態を示す。そして、抽出部３１は、ヘルメット画像ＨＲｇを見つけ出した場合、その代表位置ＲＰを決定する。なお、代表位置ＲＰは、ヘルメット画像ＨＲｇの大きさ、形状等から導き出される位置である。本実施例では、代表位置ＲＰは、ヘルメット画像ＨＲｇを含むヘルメット画像領域の中心画素の位置である。図１１下図は、図１１上図における白線で区切られた矩形画像領域であるヘルメット画像領域の拡大図であり、そのヘルメット画像領域の中心画素の位置が代表位置ＲＰであることを示す。
</base:Paragraphs>
      <base:Paragraphs num="0051">
  その後、抽出部３１は、例えば最近傍探索アルゴリズムを用いて代表位置ＲＰの最も近傍にある頭部画像位置ＡＰを導き出す。図１１下図は、代表位置ＲＰの近くに６つの頭部画像位置ＡＰ１～ＡＰ６が予め設定されており、そのうちの頭部画像位置ＡＰ５が代表位置ＲＰの最も近傍にある頭部画像位置ＡＰであることを示す。
</base:Paragraphs>
      <base:Paragraphs num="0052">
  そして、抽出部３１は、図１０に示す幾何学的関係を利用し、導き出した最近傍の頭部画像位置ＡＰから、仮想頭部位置ＨＰ、参照点Ｐｒ、仮想平面領域ＴＲを辿って、対応する識別処理対象画像領域ＴＲｇを抽出する。その後、抽出部３１は、抽出した識別処理対象画像領域ＴＲｇを有する識別処理対象画像を正規化して正規化画像ＴＲｇｔを生成する。
</base:Paragraphs>
      <base:Paragraphs num="0053">
  このようにして、抽出部３１は、撮像画像における人の特徴画像の位置であるヘルメット画像ＨＲｇの代表位置ＲＰと、予め設定された頭部画像位置ＡＰの１つ（頭部画像位置ＡＰ５）とを対応付けることで識別処理対象画像を抽出する。
</base:Paragraphs>
      <base:Paragraphs num="0054">
  なお、抽出部３１は、図１０に示す幾何学的関係を利用する代わりに、頭部画像位置ＡＰと参照点Ｐｒ、仮想平面領域ＴＲ、又は識別処理対象画像領域ＴＲｇとを直接的に対応付ける参照テーブルを利用し、頭部画像位置ＡＰに対応する識別処理対象画像を抽出してもよい。
</base:Paragraphs>
      <base:Paragraphs num="0055">
  また、抽出部３１は、山登り法、Mean-shift法等の最近傍探索アルゴリズム以外の他の公知のアルゴリズムを用いて代表位置ＲＰから参照点Ｐｒを導き出してもよい。例えば、山登り法を用いる場合、抽出部３１は、代表位置ＲＰの近傍にある複数の頭部画像位置ＡＰを導き出し、代表位置ＲＰとそれら複数の頭部画像位置ＡＰのそれぞれに対応する参照点Ｐｒとを紐付ける。このとき、抽出部３１は、代表位置ＲＰと頭部画像位置ＡＰが近いほど重みが大きくなるように参照点Ｐｒに重みを付ける。そして、複数の参照点Ｐｒの重みの分布を山登りし、重みの極大点に最も近い重みを有する参照点Ｐｒから識別処理対象画像領域ＴＲｇを抽出する。
</base:Paragraphs>
      <base:Paragraphs num="0056">
  次に、図１２を参照し、コントローラ３０の抽出部３１が識別処理対象画像を抽出する処理（以下、「画像抽出処理」とする。）の一例について説明する。なお、図１２は、画像抽出処理の一例の流れを示すフローチャートである。
</base:Paragraphs>
      <base:Paragraphs num="0057">
  最初に、抽出部３１は、撮像画像内でヘルメット画像を探索する（ステップＳＴ１）。本実施例では、抽出部３１は、前段画像認識処理により後方カメラ４０Ｂの撮像画像をラスタスキャンしてヘルメット画像を見つけ出す。
</base:Paragraphs>
      <base:Paragraphs num="0058">
  撮像画像でヘルメット画像ＨＲｇを見つけ出した場合（ステップＳＴ１のＹＥＳ）、抽出部３１は、ヘルメット画像ＨＲｇの代表位置ＲＰを取得する（ステップＳＴ２）。
</base:Paragraphs>
      <base:Paragraphs num="0059">
  その後、抽出部３１は、取得した代表位置ＲＰの最近傍にある頭部画像位置ＡＰを取得する（ステップＳＴ３）。
</base:Paragraphs>
      <base:Paragraphs num="0060">
  その後、抽出部３１は、取得した頭部画像位置ＡＰに対応する識別処理対象画像を抽出する（ステップＳＴ４）。本実施例では、抽出部３１は、図１０に示す幾何学的関係を利用し、撮像画像における頭部画像位置ＡＰ、実空間における仮想頭部位置ＨＰ、実空間における人の想定立ち位置としての参照点Ｐｒ、及び、実空間における仮想平面領域ＴＲの対応関係を辿って識別処理対象画像を抽出する。
</base:Paragraphs>
      <base:Paragraphs num="0061">
  なお、抽出部３１は、撮像画像でヘルメット画像ＨＲｇを見つけ出さなかった場合には（ステップＳＴ１のＮＯ）、識別処理対象画像を抽出することなく、処理をステップＳＴ５に移行させる。
</base:Paragraphs>
      <base:Paragraphs num="0062">
  その後、抽出部３１は、撮像画像の全体にわたってヘルメット画像を探索したかを判定する（ステップＳＴ５）。
</base:Paragraphs>
      <base:Paragraphs num="0063">
  撮像画像の全体を未だ探索していないと判定した場合（ステップＳＴ５のＮＯ）、抽出部３１は、撮像画像の別の領域に対し、ステップＳＴ１～ステップＳＴ４の処理を実行する。
</base:Paragraphs>
      <base:Paragraphs num="0064">
  一方、撮像画像の全体にわたるヘルメット画像の探索を完了したと判定した場合（ステップＳＴ５のＹＥＳ）、抽出部３１は今回の画像抽出処理を終了させる。
</base:Paragraphs>
      <base:Paragraphs num="0065">
  このように、抽出部３１は、最初にヘルメット画像ＨＲｇを見つけ出し、見つけ出したヘルメット画像ＨＲｇの代表位置ＲＰから、頭部画像位置ＡＰ、仮想頭部位置ＨＰ、参照点（想定立ち位置）Ｐｒ、仮想平面領域ＴＲを経て識別処理対象画像領域ＴＲｇを特定する。そして、特定した識別処理対象画像領域ＴＲｇを有する識別処理対象画像を抽出して正規化することで、所定サイズの正規化画像ＴＲｇｔを生成できる。
</base:Paragraphs>
      <base:Paragraphs num="0066">
  以上の構成により、周辺監視システム１００の抽出部３１は、撮像画像における特徴画像としてのヘルメット画像を見つけ出し、そのヘルメット画像の代表位置ＲＰと所定画像位置としての頭部画像位置ＡＰの１つとを対応付けることで識別処理対象画像を抽出する。そのため、簡易なシステム構成で後段画像認識処理の対象となる画像部分を絞り込むことができる。
</base:Paragraphs>
      <base:Paragraphs num="0067">
  なお、抽出部３１は、最初に撮像画像からヘルメット画像ＨＲｇを見つけ出し、そのヘルメット画像ＨＲｇの代表位置ＲＰに対応する頭部画像位置ＡＰの１つを導き出し、その頭部画像位置ＡＰの１つに対応する識別処理対象画像を抽出してもよい。或いは、抽出部３１は、最初に頭部画像位置ＡＰの１つを取得し、その頭部画像位置ＡＰの１つに対応する特徴画像の位置を含む所定領域であるヘルメット画像領域内にヘルメット画像が存在する場合に、その頭部画像位置ＡＰの１つに対応する識別処理対象画像を抽出してもよい。
</base:Paragraphs>
      <base:Paragraphs num="0068">
  また、抽出部３１は、図１０に示すような所定の幾何学的関係を利用し、撮像画像におけるヘルメット画像の代表位置ＲＰから識別処理対象画像を抽出してもよい。この場合、所定の幾何学的関係は、撮像画像における識別処理対象画像領域ＴＲｇと、識別処理対象画像領域ＴＲｇに対応する実空間における仮想平面領域ＴＲと、仮想平面領域ＴＲに対応する実空間における参照点Ｐｒ（人の想定立ち位置）と、参照点Ｐｒに対応する仮想頭部位置ＨＰ（人の想定立ち位置に対応する人の特徴的な部分の実空間における位置である仮想特徴位置）と、仮想頭部位置ＨＰに対応する撮像画像における頭部画像位置ＡＰ（仮想特徴位置に対応する撮像画像における所定画像位置）との幾何学的関係を表す。
</base:Paragraphs>
      <base:Paragraphs num="0069">
  ここで再び図２を参照し、コントローラ３０の他の機能要素についての説明を継続する。
</base:Paragraphs>
      <base:Paragraphs num="0070">
  追跡部３３は、識別部３２が所定時間毎に出力する識別結果を追跡して最終的な人検知結果を出力する機能要素である。本実施例では、追跡部３３は、連続する所定回数分の同一人に関する識別結果が所定条件を満たす場合に、対応する人候補画像が人画像であると判定する。すなわち、対応する三次元位置（実在位置）に人が存在すると判定する。同一人であるか否かはその実在位置に基づいて判定される。具体的には、追跡部３３は、識別部３２による１回目の識別処理において人画像であると識別された画像に写る人の実在位置（参照点ＰｒＩ）に基づいて所定時間内にその人が到達可能な範囲を導き出す。到達可能な範囲は、ショベルの最大旋回速度、ショベルの最大走行速度、人の最大移動速度等に基づいて設定される。そして、２回目の識別処理において人画像であると識別された画像に写る人の実在位置（参照点ＰｒＩＩ）がその範囲内であれば同一人であると判定する。３回目以降の識別処理についても同様である。そして、追跡部３３は、例えば、連続する６回の識別結果のうちの４回で同一人の人画像であると識別された場合に、対応する三次元位置に人が存在すると判定する。また、１回目の識別処理において人画像であると識別された場合であっても、その後の連続する３回の識別処理において同一人の人画像が識別されなかった場合には、対応する三次元位置には人が存在しないと判定する。
</base:Paragraphs>
      <base:Paragraphs num="0071">
  このように、抽出部３１、識別部３２、及び追跡部３３の組み合わせは、撮像装置４０の撮像画像に基づいてショベルの周辺に人が存在するか否かを検知する人検知部３４を構成する。
</base:Paragraphs>
      <base:Paragraphs num="0072">
  この構成により、人検知部３４は、誤報（人が存在しないにもかかわらず人が存在すると判定すること）、失報（人が存在するにもかかわらず人が存在しないと判定すること）等の発生を抑制できる。
</base:Paragraphs>
      <base:Paragraphs num="0073">
  また、人検知部３４は、人画像であると識別された画像に写る人の実在位置の推移に基づき、人がショベルに近づいているのかショベルから遠ざかっているのかを判断できる。そして、人検知部３４は、その人の実在位置のショベルからの距離が所定値を下回った場合に制御部３５に制御指令を出力して警報を出力させてもよい。この場合、人検知部３４は、ショベルの動作情報（例えば旋回速度、旋回方向、走行速度、走行方向等）に応じて所定値を調整してもよい。
</base:Paragraphs>
      <base:Paragraphs num="0074">
  また、人検知部３４は少なくとも２段階の人検知状態と人非検知状態とを判別して認識してもよい。例えば、距離に関する条件、及び、信頼性に関する条件のうちの少なくとも一方が満たされた状態を第１人検知状態（警戒状態）と判断し、双方が満たされた状態を第２人検知状態（警報状態）と判断してもよい。距離に関する条件は、例えば、人画像であると識別された画像に写る人の実在位置のショベルからの距離が所定値未満であることを含む。信頼性に関する条件は、例えば、連続する６回の識別結果のうちの４回で同一人の人画像であると識別されることを含む。第１人検知状態（警戒状態）では、確度は低いがレスポンスが早い予備的な警報としての第１警報が出力される。第１警報は、例えば小音量のビープ音であり、２つの条件が何れも満たされなくなった場合に自動的に停止される。第２人検知状態（警報状態）では、確度は高いがレスポンスが遅い正式な警報としての第２警報が出力される。第２警報は、例えば大音量のメロディ音であり、少なくとも一方の条件が満たされなくなったとしても自動的に停止されず、その停止には操作者の操作が必要とされる。
</base:Paragraphs>
      <base:Paragraphs num="0075">
  制御部３５は、各種装置を制御する機能要素である。本実施例では、制御部３５は入力装置４１を介した操作者の入力に応じて各種装置を制御する。例えば、タッチパネルを通じて入力された画像切換指令に応じて車載ディスプレイの画面に表示される表示画像を切り換える。表示画像は、後方カメラ４０Ｂのスルー画像、右側方カメラ４０Ｒのスルー画像、左側方カメラ４０Ｌのスルー画像、視点変換画像等を含む。視点変換画像は、例えば、複数のカメラの撮像画像から合成される鳥瞰画像（ショベルの真上にある仮想視点から見た画像）である。
</base:Paragraphs>
      <base:Paragraphs num="0076">
  また、制御部３５は、人検知部３４を構成する追跡部３３の最終的な人検知結果に応じて各種装置を制御する。例えば、追跡部３３の最終的な人検知結果に応じて機械制御装置５１に制御指令を出力してショベルの状態を第１状態と第２状態との間で切り換える。第１状態は、ショベルの動きの制限が解除されている状態、警報の出力が停止されている状態等を含む。第２状態はショベルの動きを制限し或いは停止させている状態、警報を出力させている状態等を含む。本実施例では、制御部３５は、追跡部３３の最終的な人検知結果に基づいてショベルの周辺の所定範囲内に人が存在すると判定した場合、機械制御装置５１に制御指令を出力してショベルの状態を第１状態から第２状態に切り換える。例えば、ショベルの動きを停止させる。この場合、操作者による操作は無効にされる。操作者による操作の無効化は、例えば、操作装置を反応しない状態にすることで実現される。具体的には、ゲートロック弁に制御指令を出力して操作装置を油圧システムから切り離すことで無操作状態を強制的に創出してショベルの動きを停止させる。或いは、エンジン制御装置に制御指令を出力してエンジンを停止させてもよい。或いは、油圧アクチュエータに流入する作動油の流量を制御する制御弁に制御指令を出力して制御弁の開口面積、開口面積変化速度等を変化させることで油圧アクチュエータの動きを制限してもよい。この場合、最大旋回速度、最大走行速度等が低減される。また、制御弁を閉じることで油圧アクチュエータの動きを停止させてもよい。
</base:Paragraphs>
      <base:Paragraphs num="0077">
  また、制御部３５は、ショベルの状態を第２状態とした後で所定の解除条件が満たされた場合にショベルの状態を第１状態に戻す。すなわち、ショベルの動きを制限し或いは停止させた後で所定の解除条件が満たされた場合にその制限又は停止を解除する。所定の解除条件は、例えば、「ショベル周辺の所定範囲内に人が存在しないと判定すること」（以下、「第１解除条件」とする。）を含む。また、所定の解除条件は、例えば、「ショベルが動き出さない状態が確保されていること」（以下、「第２解除条件」とする。）を追加的に含む。また、所定の解除条件は、「ショベル周辺に人がいないことが操作者によって確認されたこと」（以下、「第３解除条件」とする。）を含んでいてもよい。なお、本実施例では、ショベルの動きが制限或いは停止されているか否か、第１解除条件、第２解除条件、第３解除条件のそれぞれが満たされているか否かはフラグを用いて管理される。
</base:Paragraphs>
      <base:Paragraphs num="0078">
  第１解除条件は、例えば、「人検知部３４を構成する追跡部３３の最終的な人検知結果に基づいて制御部３５がショベル周辺の所定範囲内に人が存在しないと判定すること」を含む。
</base:Paragraphs>
      <base:Paragraphs num="0079">
  第２解除条件は、例えば、「全ての操作装置が所定時間以上にわたって中立位置になっていること」、「ゲートロックレバーが下ろされていること（操作装置が無効となっていること）」、「全ての操作装置から操作者の手足が離されていること」、「所定の解除操作が行われたこと」等を含む。「全ての操作装置が中立位置になっていること」は、例えば、各操作装置からの指令の有無、各操作装置の操作量を検出するセンサの出力値等に基づいて制御部３５が検知する。「所定時間以上にわたって」という条件は瞬間的に中立位置になっただけで第２解除条件が満たされてしまうのを防止する効果がある。「操作装置から操作者の手足が離されていること」は、例えば、運転室内を撮像するカメラの撮像画像、操作装置（例えば操作レバーのグリップ）に取り付けられた静電センサの出力等に基づいて制御部３５が検知する。「所定の解除操作が行われたこと」は、例えば、車載ディスプレイの画面に「ショベルが動き出さない状態が確保されていますか？」といったメッセージが表示された状態で確認ボタン（例えばホーンボタン又は同じ画面上に表示されたソフトウェアボタン）が押下された場合に制御部３５が検知する。制御部３５は、例えば、運転席にあるレバー、ボタン、パネル等に対する操作入力といった操作者による解除操作が行われた場合に「ショベルが動き出さない状態が確保されている」と判断してもよい。
</base:Paragraphs>
      <base:Paragraphs num="0080">
  第３解除条件は、例えば、車載ディスプレイの画面に「ショベル周辺に人がいないことを確認しましたか？」といったメッセージが表示された状態で確認ボタンが押下された場合に満たされる。なお、第３解除条件は省略されてもよい。
</base:Paragraphs>
      <base:Paragraphs num="0081">
  所定の解除条件に第３解除条件が含まれる場合、第１解除条件と第２解除条件が満たされると、ショベルは制限解除可能状態となる。制限解除可能状態は、ショベル周辺に人がいないことを操作者が確認しさえすれば制限を解除できる状態を意味する。
</base:Paragraphs>
      <base:Paragraphs num="0082">
  第１解除条件、第２解除条件、及び第３解除条件のそれぞれが満たされる順番に制限はない。例えば、第３解除条件、第２解除条件、第１解除条件の順で条件が満たされた場合であっても、制御部３５はショベルの動きの制限又は停止を解除する。
</base:Paragraphs>
      <base:Paragraphs num="0083">
  また、制御部３５は、所定の解除条件が満たされた後で所定の待ち時間が経過したときにその制限又は停止を解除してもよい。急な解除によって操作者を慌てさせることがないようにするためである。
</base:Paragraphs>
      <base:Paragraphs num="0084">
  また、制御部３５は、ショベルの動きを制限し或いは停止させた場合、出力装置５０としての車載ディスプレイに制御指令を出力し、その原因となった人画像が含まれる撮像画像を表示させてもよい。例えば、左側方カメラ４０Ｌの撮像画像のみに人画像が含まれる場合、左側方カメラ４０Ｌのスルー画像を単独で表示させてもよい。或いは、左側方カメラ４０Ｌの撮像画像と後方カメラ４０Ｂの撮像画像のそれぞれに人画像が含まれる場合、２つのカメラのそれぞれのスルー画像を並べて同時に表示させてもよく、２つのカメラの撮像画像を含む１つの合成画像（例えば視点変換画像）を表示させてもよい。また、制限中又は停止中であることを表す画像、解除方法のガイダンス等を表示させてもよい。また、人画像であると識別された人候補画像に対応する画像部分を強調表示してもよい。例えば、識別処理対象画像領域ＴＲｇの輪郭線を所定色で表示してもよい。また、所定の解除条件が満たされた後の待ち時間を設定している場合には、所定の解除条件が満たされたときに待ち時間が存在することを操作者に知らせてもよい。例えば、待ち時間が存在する旨を表示した上で、待ち時間のカウントダウンを表示してもよい。また、待ち時間中に警報を出力している場合には待ち時間の経過と共にその警報の音量を徐々に小さくしてもよい。
</base:Paragraphs>
      <base:Paragraphs num="0085">
  また、制御部３５は、ショベルの動きを制限し或いは停止させた場合、出力装置５０としての車載スピーカに制御指令を出力し、その原因となった人が存在する側で警報を出力させてもよい。この場合、車載スピーカは、例えば、運転室内の右壁に設置された右側方スピーカ、左壁に設置された左側方スピーカ、及び後壁に設置された後方スピーカで構成される。そして、制御部３５は、左側方カメラ４０Ｌの撮像画像のみに人画像が含まれる場合、左側方スピーカのみから警報を出力させる。或いは、制御部３５は複数のスピーカを含むサラウンドシステムを用いて音を定位させてもよい。
</base:Paragraphs>
      <base:Paragraphs num="0086">
  また、制御部３５は、人検知部３４が人候補画像を人画像であると識別した場合に、ショベルの動きを制限し或いは停止させることなく警報のみを出力させてもよい。この場合も制御部３５は上述のように距離に関する条件及び信頼性に関する条件のうちの少なくとも一方が満たされた状態を第１人検知状態（警戒状態）と判断し、双方が満たされた状態を第２人検知状態（警報状態）と判断してもよい。そして、制御部３５は、ショベルの動きを制限し或いは停止させた場合と同様に、所定の解除条件が満たされた場合に第２人検知状態（警報状態）での警報を停止させてもよい。自動的に停止され得る第１人検知状態（警戒状態）での警報とは異なり、第２人検知状態（警報状態）での警報の停止には操作者の操作が必要とされるためである。
</base:Paragraphs>
      <base:Paragraphs num="0087">
  次に、図１３を参照し、コントローラ３０の制御部３５がショベルの周辺を監視する処理（以下、「周辺監視処理」とする。）の一例について説明する。図１３は、周辺監視処理の一例の流れを示すフローチャートであり、コントローラ３０は所定の制御周期で繰り返しこの周辺監視処理を実行する。
</base:Paragraphs>
      <base:Paragraphs num="0088">
  最初に、制御部３５は、ショベル周辺に人が存在するか否かを判定する（ステップＳＴ１１）。本実施例では、制御部３５は、追跡部３３の最終的な人検知結果に基づいてショベル周辺に人が存在するか否かを判定する。
</base:Paragraphs>
      <base:Paragraphs num="0089">
  その後、ショベル周辺に人が存在すると判定した場合（ステップＳＴ１１のＹＥＳ）、制御部３５はショベルの動きを制限し或いは停止させる（ステップＳＴ１２）。本実施例では、制御部３５は、例えば、現在の人検知状態が第２人検知状態（警報状態）であると判断した場合にショベル周辺に人が存在すると判定してショベルの動きを停止させる。
</base:Paragraphs>
      <base:Paragraphs num="0090">
  このとき、制御部３５は出力装置５０としての車載スピーカに制御指令を出力して第２警報を出力させる。また、出力装置５０としての車載ディスプレイに制御指令を出力して制限又は停止の原因となった人画像が含まれる撮像画像を表示させる。
</base:Paragraphs>
      <base:Paragraphs num="0091">
  ショベル周辺に人が存在しないと判定した場合（ステップＳＴ１１のＮＯ）、制御部３５はショベルの動きが既に制限或いは停止されているか否かを判定する（ステップＳ１３）。本実施例では、制御部３５は、対応するフラグの値を参照してショベルの動きが既に制限或いは停止されているか否かを判定する。
</base:Paragraphs>
      <base:Paragraphs num="0092">
  ショベルの動きが既に制限或いは停止されていると判定した場合（ステップＳＴ１３のＹＥＳ）、制御部３５は、その制限又は停止を解除するための処理（以下、「制限解除処理」とする。）を実行する（ステップＳＴ１４）。
</base:Paragraphs>
      <base:Paragraphs num="0093">
  ショベルの動きが未だ制限或いは停止されていないと判定した場合（ステップＳＴ１３のＮＯ）、制御部３５は、制限解除処理を実行することなく、今回のショベル周辺監視処理を終了させる。
</base:Paragraphs>
      <base:Paragraphs num="0094">
  次に、図１４を参照し、コントローラ３０の制御部３５がショベルの動きの制限又は停止を解除する処理について説明する。図１４は制限解除処理の一例の流れを示すフローチャートである。
</base:Paragraphs>
      <base:Paragraphs num="0095">
  最初に、制御部３５は第１解除条件が満たされたか否かを判定する（ステップＳＴ２１）。本実施例では、制御部３５は、ショベル周辺の所定範囲内に人が存在しないか否かを判定する。具体的には、現在の人検知状態が第２人検知状態（警報状態）を脱したか否かを判定する。第１人検知状態（警戒状態）及び第２人検知状態（警報状態）を脱したか否かを判定してもよい。
</base:Paragraphs>
      <base:Paragraphs num="0096">
  第１解除条件が満たされたと判定した場合（ステップＳＴ２１のＹＥＳ）、制御部３５は第２解除条件が満たされたか否かを判定する（ステップＳＴ２２）。本実施例では、制御部３５は、ショベルが動き出さない状態が確保されているか否かを判定する。具体的には、ゲートロックレバーが下ろされているか否か（操作装置が無効となっているかいなか）を判定する。
</base:Paragraphs>
      <base:Paragraphs num="0097">
  第２解除条件が満たされたと判定した場合（ステップＳＴ２２のＹＥＳ）、制御部３５は第３解除条件が満たされたか否かを判定する（ステップＳＴ２３）。本実施例では、制御部３５は、ショベル周辺に人がいないことが操作者によって確認されたか否かを判定する。具体的には、車載ディスプレイの画面に「ショベル周辺に人がいないことを確認しましたか？」といったメッセージが表示された状態で確認ボタンが押下されたか否かを判定する。
</base:Paragraphs>
      <base:Paragraphs num="0098">
  第３解除条件が満たされたと判定した場合（ステップＳＴ２３のＹＥＳ）、制御部３５はショベルの動きの制限又は停止を解除する（ステップＳＴ２４）。
</base:Paragraphs>
      <base:Paragraphs num="0099">
  このとき、制御部３５は、出力装置５０としての車載スピーカに制御指令を出力して第２警報の出力を停止させる。また、出力装置５０としての車載ディスプレイに制御指令を出力して制限又は停止の原因となった人画像が含まれる撮像画像の表示を停止させる。例えば、第２警報が出力される前に表示されていたスルー画像を再表示させる。また、制御部３５は、ショベルの動きの制限又は停止が解除されたことを伝えるメッセージを表示させてもよい。
</base:Paragraphs>
      <base:Paragraphs num="0100">
  なお、制御部３５は、第１解除条件が満たされていないと判定した場合（ステップＳＴ２１のＮＯ）、第２解除条件が満たされていないと判定した場合（ステップＳＴ２２のＮＯ）、

第３解除条件が満たされていないと判定した場合には（ステップＳＴ２３のＮＯ）、ショベルの動きの制限又は停止を解除することなく、今回の制限解除処理を終了させる。
</base:Paragraphs>
      <base:Paragraphs num="0101">
  以上の構成により、コントローラ３０は、ショベル周辺に人が存在すると判定した場合にショベルの動きを制限し或いは停止させることができる。
</base:Paragraphs>
      <base:Paragraphs num="0102">
  また、コントローラ３０は、ショベルの動きを制限し或いは停止させた後でショベル周辺に人が存在しないと判定した場合には、ショベルが動き出さない状態が確保されていると判定したときに限り、その制限又は停止を解除できる。また、コントローラ３０は、ショベルが動き出さない状態が確保されていると判定し、且つ、ショベル周辺に人がいないことが操作者によって確認されたと判定したときに限り、その制限又は停止を解除できる。そのため、コントローラ３０は、その制限又は停止を解除した際にショベルが意図せず動き出してしまうのを防止できる。
</base:Paragraphs>
      <base:Paragraphs num="0103">
  次に、図１５を参照し、周辺監視処理の実行中に車載ディスプレイに表示される出力画像の１例について説明する。図１５は後方カメラ４０Ｂの撮像画像に基づいて生成される出力画像の例である。図１５（Ａ）はショベル周辺の所定範囲内に人がいないときの出力画像の例を示し、図１５（Ｂ）は第１人検知状態での出力画像の例を示し、図１５（Ｃ）は第２人検知状態での出力画像の例を示す。
</base:Paragraphs>
      <base:Paragraphs num="0104">
  具体的には、図１５の出力画像はカメラ画像部分Ｇ１及びインジケータ部分Ｇ２を含む。カメラ画像部分Ｇ１は１又は複数のカメラの撮像画像に基づいて生成される画像を表示する部分である。インジケータ部分Ｇ２はショベル周辺における複数の領域のそれぞれの人検知状態／人非検知状態を表示する部分である。カメラ画像部分Ｇ１において、カメラ画像上に重畳表示される線分Ｌ１はショベルからの距離が所定の第１距離（例えば５メートル）であることを示す。また、カメラ画像上に重畳表示される線分Ｌ２はショベルからの距離が所定の第２距離（例えば２．５メートル）であることを示す。インジケータ部分Ｇ２において、ショベルアイコンＣＧ１の周囲に描かれる部分円の外周線Ｌ１ｇはショベルからの距離が所定の第１距離（例えば５メートル）であることを示し、カメラ画像部分Ｇ１の線分Ｌ１に対応する。また、ショベルアイコンＣＧ１の周囲に描かれる部分矩形の外周線Ｌ２ｇはショベルからの距離が所定の第２距離（例えば２．５メートル）であることを示し、カメラ画像部分Ｇ１の線分Ｌ２に対応する。
</base:Paragraphs>
      <base:Paragraphs num="0105">
  部分円は６つの領域Ａ１～Ａ６に分割され、部分矩形は３つの領域Ｂ１～Ｂ３に分割されている。
</base:Paragraphs>
      <base:Paragraphs num="0106">
  図１５（Ａ）に示す状態では、コントローラ３０はショベルの右後方に存在する人を検知している。しかしながら、コントローラ３０は、その人の実在位置が第１距離以遠であるため、その人の画像を強調表示しておらず、第１警報も出力していない。但し、コントローラ３０は、対応する識別処理対象画像領域ＴＲｇの輪郭線を白色枠として表示する等、その人の画像を強調表示してもよく、第１警報を出力してもよい。また、既に人を検知しているか否かにかかわらず、「周辺監視処理実行中」等のメッセージを表示してもよい。周辺監視処理が実行中であることを操作者が認識できるようにするためである。
</base:Paragraphs>
      <base:Paragraphs num="0107">
  図１５（Ｂ）に示す第１人検知状態では、コントローラ３０はショベルの右後方の第１距離以内で且つ第２距離以遠に存在する人を検知している。そのため、コントローラ３０は、その人の画像を強調表示し且つ第１警報を出力している。具体的には、コントローラ３０は、カメラ画像部分Ｇ１において、対応する識別処理対象画像領域ＴＲｇの輪郭線を黄色枠Ｆ１として表示する。また、インジケータ部分Ｇ２において、その人の実在位置に対応する領域Ａ４を黄色で表示する。但し、黄色枠の表示は省略されてもよい。また、第１人検知状態（警戒状態）であることを伝えるメッセージを表示させてもよい。
</base:Paragraphs>
      <base:Paragraphs num="0108">
  図１５（Ｃ）に示す第２人検知状態では、コントローラ３０はショベルの右後方の第２距離以内に存在する人を検知している。そのため、コントローラ３０は、その人の画像を強調表示し且つ第２警報を出力している。具体的には、コントローラ３０は、カメラ画像部分Ｇ１において、対応する識別処理対象画像領域ＴＲｇの輪郭線を赤色枠Ｆ２として表示する。また、インジケータ部分Ｇ２において、その人の実在位置に対応する領域Ｂ２を赤色で表示する。また、コントローラ３０は、ショベルの動きを制限した上で、第２人検知状態（警報状態）であることを伝えるメッセージ「ショベル動作制限中」を点滅表示させている。但し、第２人検知状態（警報状態）であることを伝えるメッセージの表示は省略されてもよい。
</base:Paragraphs>
      <base:Paragraphs num="0109">
  また、図１５（Ａ）～図１５（Ｃ）では、画面の左側にカメラ画像部分Ｇ１が表示され、画面の右側にインジケータ部分Ｇ２が表示されるが、画面の右側にカメラ画像部分Ｇ１が表示され、画面の左側にインジケータ部分Ｇ２が表示されてもよい。また、上下に分割された画面の一方にカメラ画像部分Ｇ１が表示され、他方にインジケータ部分Ｇ２が表示されてもよい。また、インジケータ部分Ｇ２の表示は省略されてもよい。
</base:Paragraphs>
      <base:Paragraphs num="0110">
  また、領域Ａ１～Ａ６のそれぞれの拡がり角度は４５度であり、領域Ｂ１～Ｂ３のそれぞれの拡がり角度は９０度である。この拡がり角度の違いは、第１人検知状態（警戒状態）と第２人検知状態（警報状態）の性質の違いに基づく。具体的には、第１人検知状態（警戒状態）は、確度は低いがレスポンスが早い予備的な警報が出力される状態であり、ショベルから比較的離れたところの比較的広い空間範囲が監視範囲となっている。そのため、領域Ａ１～Ａ６の拡がり角度を大きくすると、それぞれの領域に対応する監視範囲がその表示範囲と共に大きくなり、第１警報の原因となった人の実在位置が分かり難くなってしまう。広い監視範囲のどこにいても同じ表示結果となってしまうためである。一方で、第２人検知状態（警報状態）は、確度は高いがレスポンスが遅い正式な警報が出力される状態であり、ショベルから比較的近いところの比較的狭い空間範囲が監視範囲となっている。そのため、領域Ｂ１～Ｂ３の拡がり角度を小さくすると、それぞれの領域に対応する監視範囲がその表示範囲と共に小さくなり、第２警報の原因となった人が何れの方向にいるのかが分かり難くなってしまう。表示範囲が小さくて見え難くなってしまうためである。そのため、望ましくは、図１５（Ａ）～図１５（Ｃ）に示すように、領域Ａ１～Ａ６のそれぞれの拡がり角度は領域Ｂ１～Ｂ３のそれぞれの拡がり角度よりも小さくなるように設定される。
</base:Paragraphs>
      <base:Paragraphs num="0111">
  また、図１５（Ａ）～図１５（Ｃ）では、後方カメラ４０Ｂのスルー画像が表示されているときに後方カメラ４０Ｂの撮像画像で人画像が検知された場合について説明する。しかしながら、上述の説明は、後方カメラ４０Ｂのスルー画像が表示されているときに左側方カメラ４０Ｌ及び右側方カメラ４０Ｒの少なくとも一方の撮像画像で人画像が検知された場合にも同様に適用される。その場合、カメラ画像部分Ｇ１に表示される出力画像は、後方カメラ４０Ｂのスルー画像から別のカメラのスルー画像又は複数のカメラの撮像画像から合成される視点変換画像に自動的に切り換えられてもよい。例えば、コントローラ３０は、後方カメラ４０Ｂのスルー画像が表示されているときに左側方カメラ４０Ｌの撮像画像で人画像が検知された場合、カメラ画像部分Ｇ１に表示される出力画像を左側方カメラ４０Ｌのスルー画像に切り換えてもよい。
</base:Paragraphs>
      <base:Paragraphs num="0112">
  次に、図１６を参照し、検知状態と枠及び領域の表示色との関係について説明する。図１６は、検知状態と枠及び領域の表示色との対応関係を示す対応テーブルである。
</base:Paragraphs>
      <base:Paragraphs num="0113">
  対応テーブルの１行目は、検知状態が第１人検知状態（警戒状態）でも第２人検知状態（警報状態）でもない場合には、識別処理対象画像領域の輪郭線を表示せず、インジケータ部分Ｇ２の何れの領域をも着色しないことを表す。
</base:Paragraphs>
      <base:Paragraphs num="0114">
  ２行目は、検知状態が警戒状態である場合には、警戒状態をもたらす原因となった人画像に対応する識別処理対象画像領域の輪郭線が黄色枠として表示され、且つ、領域Ａ１～Ａ６の何れかが黄色で表示されることを表す。
</base:Paragraphs>
      <base:Paragraphs num="0115">
  ３行目は、検知状態が警報状態である場合には、警報状態をもたらす原因となった人画像に対応する識別処理対象画像領域の輪郭線が赤色枠として表示され、且つ、領域Ｂ１～Ｂ３の何れかが赤色で表示されることを表す。
</base:Paragraphs>
      <base:Paragraphs num="0116">
  ４行目は、検知状態が警戒状態で且つ警報状態である場合には、警戒状態をもたらす原因となった人画像に対応する輪郭線が黄色枠で表示され、且つ、警報状態をもたらす原因となった人画像に対応する輪郭線が赤色枠で表示されることを表す。また、領域Ａ１～Ａ６のうち警戒状態をもたらす原因となった人画像に対応する領域が黄色で表示され、領域Ｂ１～Ｂ３のうち警報状態をもたらす原因となった人画像に対応する領域が赤色で表示されることを表す。
</base:Paragraphs>
      <base:Paragraphs num="0117">
  以上の構成により、コントローラ３０は、ショベル周辺に人が存在すると判定した場合に警報を出力し且つその人の画像部分を強調表示する。そのため、操作者は警報の原因となった人を画面で確認できる。また、操作者は誤報が発生した場合にもその誤報の原因となったものが何であるかを画面で確認できる。
</base:Paragraphs>
      <base:Paragraphs num="0118">
  また、コントローラ３０は、第１人検知状態（警戒状態）となった場合に初めてカメラ画像部分Ｇ１に人検知マーカとしての枠画像を表示し、且つ、インジケータ部分Ｇ２の対応する領域の色を変化させる。そのため、人画像として識別されたがその信頼性が未だ低い人候補画像に対応する枠画像までもが表示されてしまい、表示画像が複雑化してしまうのを防止できる。なお、上述の実施例では、人検知マーカとして枠画像を表示するが、反転表示画像等の他の強調画像が人検知マーカとして採用されてもよい。
</base:Paragraphs>
      <base:Paragraphs num="0119">
  また、第１人検知状態（警戒状態）をもたらす原因となった人の画像と、第２人検知状態（警報状態）をもたらす原因となった人の画像とを区別可能に強調表示する。また、カメラ画像部分Ｇ１における枠画像の色とインジケータ部分Ｇ２における領域の色とを対応させる。そのため、操作者は第２警報の原因となった人を画面で確認できる。また、上述の実施例では、コントローラ３０は、カメラ画像部分Ｇ１における枠画像の色、及び、インジケータ部分Ｇ２における領域の色を検知状態に応じて異ならせる。但し、コントローラ３０は、点滅・点灯状態、透過率等の色以外の属性を検知状態に応じて異ならせてもよい。
</base:Paragraphs>
      <base:Paragraphs num="0120">
  次に、図１７を参照し、周辺監視処理の実行中に車載ディスプレイに表示される出力画像の別の１例について説明する。図１７は後方カメラ４０Ｂ、左側方カメラ４０Ｌ、及び右側方カメラ４０Ｒのそれぞれの撮像画像に基づいて生成される出力画像としての視点変換画像の例である。図１７は、第１人検知状態と第２人検知状態とが併存する場合の出力画像の例を示す。図１７の出力画像は図１５のカメラ画像部分Ｇ１に対応する視点変換画像部分Ｇ３を含む。図１５のインジケータ部分Ｇ２に対応する部分は視点変換画像部分Ｇ３に統合されている。具体的には、図１５のショベルアイコンＣＧ１は図１７のショベルアイコンＣＧ２に対応し、図１５の領域Ａ１～Ａ６は図１７の領域Ｃ１～Ｃ６に対応する。また、図１５の領域Ｂ１は図１７の領域Ｃ１及びＣ２の組み合わせに対応し、図１５の領域Ｂ２は図１７の領域Ｃ３及びＣ４の組み合わせに対応し、図１５の領域Ｂ３は図１７の領域Ｃ５及びＣ６の組み合わせに対応する。視点変換画像上に重畳表示される線分Ｌ３はショベルからの距離が所定の第３距離（例えば２．５メートル）であることを示す。
</base:Paragraphs>
      <base:Paragraphs num="0121">
  図１７に示す検知状態では、コントローラ３０はショベルの左側方の第１距離（例えば５メートル）以内で且つ第３距離以遠に存在する人（第１人検知状態をもたらす原因となった人）を検知している。また、ショベルの後方の第３距離以内に存在する人（第２人検知状態をもたらす原因となった人）を検知している。そのため、コントローラ３０は、それらの人の画像を強調表示し、第２警報を出力し、且つ、ショベルの動きを制限している。具体的には、コントローラ３０は、第１人検知状態をもたらす原因となった人に対応する参照点Ｐｒの位置に人検知マーカとしての黄色円ＭＡ１を表示し、且つ、その位置に対応する領域Ｃ２を黄色で表示する。また、第２人検知状態をもたらす原因となった人に対応する参照点Ｐｒの位置に人検知マーカとしての赤色円ＭＡ２を表示し、且つ、その位置に対応する領域Ｃ３及びＣ４の組み合わせを赤色で表示する。また、コントローラ３０は、ショベルの動きを制限した上で、第２人検知状態（警報状態）であることを伝えるメッセージ「ショベル動作制限中」を点滅表示させてもよい。また、黄色円ＭＡ１の表示は省略されてもよい。画面を見易くするためである。
</base:Paragraphs>
      <base:Paragraphs num="0122">
  次に、図１８を参照し、周辺監視処理の実行中に車載ディスプレイに表示される出力画像の更に別の１例について説明する。図１８は、後方カメラ４０Ｂ、左側方カメラ４０Ｌ、及び右側方カメラ４０Ｒのそれぞれの撮像画像に基づいて生成される視点変換画像を含む出力画像の例である。図１８は、図１７の場合と同様、第１人検知状態と第２人検知状態とが併存する場合の出力画像の例を示す。図１８の出力画像はインジケータ部分Ｇ２と視点変換画像部分Ｇ３を含む。ショベルアイコンＣＧ１の周囲に描かれる部分矩形の外周線Ｌ２ｇはショベルからの距離が所定の第３距離（例えば２．５メートル）であることを示し、視点変換画像部分Ｇ３の線分Ｌ３に対応する。
</base:Paragraphs>
      <base:Paragraphs num="0123">
  図１８に示す検知状態では、コントローラ３０はショベルの左側方の第１距離（例えば５メートル）以内で且つ第３距離以遠に存在する人（第１人検知状態をもたらす原因となった人）を検知している。また、ショベルの後方の第３距離以内に存在する人（第２人検知状態をもたらす原因となった人）を検知している。そのため、コントローラ３０は、それらの人の画像を強調表示し、第２警報を出力し、且つ、ショベルの動きを制限している。具体的には、コントローラ３０は、第１人検知状態をもたらす原因となった人に対応する参照点Ｐｒの位置に人検知マーカとしての黄色円ＭＡ１を表示し、且つ、その位置に対応するインジケータ部分Ｇ２の領域Ａ２を黄色で表示する。また、第２人検知状態をもたらす原因となった人に対応する参照点Ｐｒの位置に人検知マーカとしての赤色円ＭＡ２を表示し、且つ、その位置に対応するインジケータ部分Ｇ２の領域Ｂ２を赤色で表示する。また、コントローラ３０は、ショベルの動きを制限した上で、第２人検知状態（警報状態）であることを伝えるメッセージ「ショベル動作制限中」を点滅表示させている。なお、黄色円ＭＡ１の表示は省略されてもよい。画面を見易くするためである。
</base:Paragraphs>
      <base:Paragraphs num="0124">
  以上の構成により、コントローラ３０は、図１５の出力画像を表示した場合と同様の効果を実現できる。
</base:Paragraphs>
      <base:Paragraphs num="0125">
  このように、コントローラ３０は、ショベル周辺に人が存在すると判定した場合にショベルの動きを制限し或いは停止させ且つその人の画像を表示する。そして、ショベルの動きを制限し或いは停止させた後でショベル周辺に人が存在しないと判定した場合には、ショベルが動き出さない状態が確保されていると判定したときに限り、その制限又は停止を解除できると判定する。そして、所定の待ち時間が経過したときにその制限又は停止を実際に解除する。そのため、人の検知に応じて実行されたショベルの動作制限をより適切に解除できる。
</base:Paragraphs>
      <base:Paragraphs num="0126">
  また、コントローラ３０は、ショベルの動きを制限し或いは停止させた場合、その原因となった人が存在する側から操作者に向けて警報を出力させることができる。そのため、操作者が車載ディスプレイの画面を見る前に、人が存在する方向を操作者に認識させることができる。操作者は、警報が聞こえてきた方向によって人が存在する方向を聴覚的に認識した後で車載ディスプレイの画面を見ることで、認識した通りの方向に人が存在することを視覚的に確認できる。このように、コントローラ３０は、警報と表示の連携で人が存在する方向を操作者に知らせるため、短時間でショベル周辺の状況を操作者に認識させることができる。
</base:Paragraphs>
      <base:Paragraphs num="0127">
  警報により人が検知されたことを認識した場合であってもその人の存在方向が分からないときには操作者は先ず画面全体を見てその人が何れの方向に存在するのかを見つけ出す必要があるためである。一方で、画面を見る前にその人の存在方向が分かっているときには操作者は画面の一部（その存在方向に対応する部分）を見るだけでその人の存在を視覚的に確認できるためである。
</base:Paragraphs>
      <base:Paragraphs num="0128">
  以上、本発明の好ましい実施例について詳説したが、本発明は、上述した実施例に制限されることはなく、本発明の範囲を逸脱することなしに上述した実施例に種々の変形及び置換を加えることができる。
</base:Paragraphs>
      <base:Paragraphs num="0129">
  例えば、上述の実施例では、ショベルの上部旋回体３の上に取り付けられる撮像装置４０の撮像画像を用いて人を検知する場合を想定するが、本発明はこの構成に限定されるものではない。移動式クレーン、固定式クレーン、リフマグ機、フォークリフト等の他の作業機械の本体部に取り付けられる撮像装置の撮像画像を用いる構成にも適用され得る。
</base:Paragraphs>
      <base:Paragraphs num="0130">
  また、上述の実施例では、３つのカメラを用いてショベルの死角領域を撮像するが、１つ、２つ、又は４つ以上のカメラを用いてショベルの死角領域を撮像してもよい。
</base:Paragraphs>
      <base:Paragraphs num="0131">
  また、上述の実施例では、撮像装置４０の撮像画像を用いて人検知が行われるが、超音波センサ、レーザレーダ、焦電センサ、ミリ波レーダ等の出力を用いて人検知が行われてもよい。
</base:Paragraphs>
      <base:Paragraphs num="0132">
  また、上述の実施例では、複数の撮像画像のそれぞれに対して個別に人検知処理が適用されるが、複数の撮像画像から生成される１つの合成画像に対して人検知処理が適用されてもよい。
</base:Paragraphs>
    </business:EmbodimentsDescription>
    <business:ReferenceSignsList>
      <base:Paragraphs num="0133">
  １・・・下部走行体  ２・・・旋回機構  ３・・・上部旋回体  ４・・・ブーム  ５・・・アーム  ６・・・バケット  ７・・・ブームシリンダ  ８・・・アームシリンダ  ９・・・バケットシリンダ  １０・・・キャビン  ３０・・・コントローラ  ３１・・・抽出部  ３２・・・識別部  ３３・・・追跡部  ３４・・・人検知部  ３５・・・制御部  ４０・・・撮像装置  ４０Ｂ・・・後方カメラ  ４０Ｌ・・・左側方カメラ  ４０Ｒ・・・右側方カメラ  ４１・・・入力装置  ５０・・・出力装置  ５１・・・機械制御装置  １００・・・周辺監視システム  ＡＰ、ＡＰ１～ＡＰ６・・・頭部画像位置  ＢＸ・・・ボックス  Ｇ１・・・カメラ画像部分  Ｇ２・・・インジケータ部分  Ｇ３・・・視点変換画像部分  ＨＤ・・・頭部  ＨＰ・・・仮想頭部位置  ＨＲｇ・・・ヘルメット画像  Ｍ１、Ｍ２・・・マスク領域  Ｐｒ、Ｐｒ１、Ｐｒ２、Ｐｒ１０～Ｐｒ１２・・・参照点  Ｒ１・・・はみ出し領域  Ｒ２・・・車体映り込み領域  ＲＰ・・・代表位置  ＴＲ、ＴＲ１、ＴＲ２、ＴＲ１０～ＴＲ１２・・・仮想平面領域  ＴＲｇ、ＴＲｇ３、ＴＲｇ４、ＴＲｇ５・・・識別処理対象画像領域  ＴＲｇｔ、ＴＲｇｔ３、ＴＲｇｔ４、ＴＲｇｔ５・・・正規化画像
</base:Paragraphs>
    </business:ReferenceSignsList>
  </business:Description>
  <business:Drawings lang="ja" sourceDB="JP">
    <base:Figure num="0001">
      <base:Image id="000003" he="59" wi="81" file="2020092447_000003.TIF" imgContent="drawing" imgFormat="TIFF" />
    </base:Figure>
    <base:Figure num="0002">
      <base:Image id="000004" he="55" wi="77" file="2020092447_000004.TIF" imgContent="drawing" imgFormat="TIFF" />
    </base:Figure>
    <base:Figure num="0003">
      <base:Image id="000005" he="109" wi="85" file="2020092447_000005.TIF" imgContent="drawing" imgFormat="TIFF" />
    </base:Figure>
    <base:Figure num="0004">
      <base:Image id="000006" he="47" wi="70" file="2020092447_000006.TIF" imgContent="drawing" imgFormat="TIFF" />
    </base:Figure>
    <base:Figure num="0005">
      <base:Image id="000007" he="64" wi="70" file="2020092447_000007.TIF" imgContent="drawing" imgFormat="TIFF" />
    </base:Figure>
    <base:Figure num="0006">
      <base:Image id="000008" he="104" wi="85" file="2020092447_000008.TIF" imgContent="drawing" imgFormat="TIFF" />
    </base:Figure>
    <base:Figure num="0007">
      <base:Image id="000009" he="106" wi="85" file="2020092447_000009.TIF" imgContent="drawing" imgFormat="TIFF" />
    </base:Figure>
    <base:Figure num="0008">
      <base:Image id="000010" he="95" wi="85" file="2020092447_000010.TIF" imgContent="drawing" imgFormat="TIFF" />
    </base:Figure>
    <base:Figure num="0009">
      <base:Image id="000011" he="116" wi="85" file="2020092447_000011.TIF" imgContent="drawing" imgFormat="TIFF" />
    </base:Figure>
    <base:Figure num="0010">
      <base:Image id="000012" he="47" wi="70" file="2020092447_000012.TIF" imgContent="drawing" imgFormat="TIFF" />
    </base:Figure>
    <base:Figure num="0011">
      <base:Image id="000013" he="75" wi="85" file="2020092447_000013.TIF" imgContent="drawing" imgFormat="TIFF" />
    </base:Figure>
    <base:Figure num="0012">
      <base:Image id="000014" he="87" wi="70" file="2020092447_000014.TIF" imgContent="drawing" imgFormat="TIFF" />
    </base:Figure>
    <base:Figure num="0013">
      <base:Image id="000015" he="54" wi="73" file="2020092447_000015.TIF" imgContent="drawing" imgFormat="TIFF" />
    </base:Figure>
    <base:Figure num="0014">
      <base:Image id="000016" he="77" wi="70" file="2020092447_000016.TIF" imgContent="drawing" imgFormat="TIFF" />
    </base:Figure>
    <base:Figure num="0015">
      <base:Image id="000017" he="111" wi="85" file="2020092447_000017.TIF" imgContent="drawing" imgFormat="TIFF" />
    </base:Figure>
    <base:Figure num="0016">
      <base:Image id="000018" he="32" wi="70" file="2020092447_000018.TIF" imgContent="drawing" imgFormat="TIFF" />
    </base:Figure>
    <base:Figure num="0017">
      <base:Image id="000019" he="66" wi="85" file="2020092447_000019.TIF" imgContent="drawing" imgFormat="TIFF" />
    </base:Figure>
    <base:Figure num="0018">
      <base:Image id="000020" he="49" wi="85" file="2020092447_000020.TIF" imgContent="drawing" imgFormat="TIFF" />
    </base:Figure>
  </business:Drawings>
  <business:Claims lang="ja" dataFormat="original" sourceDB="JP">
    <business:Claim num="0001">
      <business:ClaimText>
  作業機械の周辺に存在する人を検知する人検知部と、

  前記作業機械に搭載された出力装置を制御する制御部と、を備え、

  前記制御部は、

    前記作業機械に取り付けられる撮像装置の撮像画像を用いて生成される出力画像をディスプレイに表示し、

    前記人検知部が前記作業機械の周辺に存在する人を検知した場合に警報を出力し、且つ、

    前記人検知部が検知した人に対応する前記出力画像上の画像部分を区別可能に表示する、

  作業機械用周辺監視システム。
</business:ClaimText>
    </business:Claim>
    <business:Claim num="0002">
      <business:ClaimText>
  前記人検知部は、少なくとも２段階の人検知状態と人非検知状態とを判別して認識し、

  前記少なくとも２段階の人検知状態は、前記作業機械からの距離に関する条件、及び、人検知結果の信頼性に関する条件のうちの少なくとも一方が満たされた第１人検知状態と、双方が満たされた第２人検知状態とを含み、

  前記制御部は、前記第１人検知状態をもたらした人に対応する前記出力画像上の画像部分と、前記第２人検知状態をもたらした人に対応する前記出力画像上の画像部分とを区別可能に表示する、

  請求項１に記載の作業機械用周辺監視システム。
</business:ClaimText>
    </business:Claim>
    <business:Claim num="0003">
      <business:ClaimText>
  前記制御部は、前記人検知部により前記第１人検知状態が認識された場合に出力する警報の内容と、前記人検知部により前記第２人検知状態が認識された場合に出力する警報の内容とを異ならせる、

  請求項２に記載の作業機械用周辺監視システム。
</business:ClaimText>
    </business:Claim>
    <business:Claim num="0004">
      <business:ClaimText>
  前記出力画像は、前記作業機械の周辺における複数の領域のそれぞれの人検知状態／人非検知状態を表すインジケータ部分を含み、

  前記制御部は、前記第１人検知状態の領域、前記第２人検知状態の領域、及び前記人非検知状態の領域を異なる色で区別可能に表示する、

  請求項２又は３に記載の作業機械用周辺監視システム。
</business:ClaimText>
    </business:Claim>
    <business:Claim num="0005">
      <business:ClaimText>
  前記出力画像は、複数の前記撮像装置のそれぞれの撮像画像を用いて合成される視点変換画像を含む、

  請求項１乃至４の何れか一項に記載の作業機械用周辺監視システム。
</business:ClaimText>
    </business:Claim>
  </business:Claims>
  <business:WOAmendedClaims id="woamendedclaims000001" lang="ja">
    <business:AmendBody lang="ja">
      <business:Description lang="ja" dataFormat="original" sourceDB="JP" correction="Y">
        <base:Paragraphs num="0001">
  本発明は、<base:Underline style="single">ショベル</base:Underline>に関する。


</base:Paragraphs>
        <base:Paragraphs num="0004">
  しかしながら、<base:Underline style="single">特許文献１は、センサが物体（人）等の監視対象を検知したときのショベルの状態の変化については言及していない</base:Underline>。


</base:Paragraphs>
        <base:Paragraphs num="0005">
  上述に鑑み、<base:Underline style="single">監視対象の検知に応じて状態を適切に変化させることができるショベル</base:Underline>の提供が望まれる。


</base:Paragraphs>
        <base:Paragraphs num="0006">
  本発明の実施例に係る<base:Underline style="single">ショベルは、走行体と、前記走行体に旋回可能に搭載された旋回体と、前記旋回体に設けられた作業アタッチメントと、を備えるショベルであって、前記旋回体に設けられ、前記ショベルの周辺の所定範囲に存在する監視対象を検知する検知部と、前記検知部の検知結果に基づき、前記ショベルの状態を、第１状態又は第２状態に切り換える制御部と、を備え、前記第１状態は、前記ショベルの操作が有効な状態、又は、警報が出力されていない状態を含み、前記第２状態は、前記ショベルの操作が無効な状態、又は、警報が出力されている状態を含み、前記制御部は、前記ショベルの状態を前記第２状態に切り換えた後で所定の条件が満たされた場合に前記ショベルの状態を前記第１状態に戻し、前記所定の条件は、前記所定範囲での前記監視対象の非検知と、前記ショベルが動き出さない状態が確保されていることと、を含む</base:Underline>。


</base:Paragraphs>
        <base:Paragraphs num="0007">
  上述の手段により、<base:Underline style="single">監視対象の検知に応じて状態を適切に変化させることができるショベル</base:Underline>が提供される。
</base:Paragraphs>
      </business:Description>
      <business:Claims lang="ja" dataFormat="original" sourceDB="JP" correction="Y">
        <business:Claim num="0001">
          <business:ClaimText>
  走行体と、

  前記走行体に旋回可能に搭載された旋回体と、

  前記旋回体に設けられた作業アタッチメントと、

  を備えるショベルであって、

  前記旋回体に設けられ、前記ショベルの周辺の所定範囲に存在する監視対象を検知する検知部と、

  前記検知部の検知結果に基づき、前記ショベルの状態を、第１状態又は第２状態に切り換える制御部と、を備え、

  前記第１状態は、前記ショベルの操作が有効な状態、又は、警報が出力されていない状態を含み、

  前記第２状態は、前記ショベルの操作が無効な状態、又は、警報が出力されている状態を含み、

  前記制御部は、前記ショベルの状態を前記第２状態に切り換えた後で所定の条件が満たされた場合に前記ショベルの状態を前記第１状態に戻し、

  前記所定の条件は、前記所定範囲での前記監視対象の非検知と、前記ショベルが動き出さない状態が確保されていることと、を含む、

  ショベル。
</business:ClaimText>
        </business:Claim>
        <business:Claim num="0002">
          <business:ClaimText>
  走行体と、

  前記走行体に旋回可能に搭載された旋回体と、

  前記旋回体に設けられた作業アタッチメントと、

  を備えるショベルであって、

  前記旋回体に設けられ、前記ショベルの周辺の所定範囲に存在する監視対象を検知する検知部と、

  前記検知部の検知結果に基づき、前記ショベルの状態を、第１状態又は第２状態に切り換える制御部と、を備え、

  前記第１状態は、前記ショベルの動きの制限が解除されている状態、又は、警報が出力されていない状態を含み、

  前記第２状態は、前記ショベルの動きが制限されている状態、又は、警報が出力されている状態を含み、

  前記制御部は、前記ショベルの状態を前記第２状態に切り換えた後で所定の条件が満たされた場合に前記ショベルの状態を前記第１状態に戻し、

  前記所定の条件は、前記所定範囲での前記監視対象の非検知と、前記ショベルが停止状態にあることと、を含む、

  ショベル。
</business:ClaimText>
        </business:Claim>
        <business:Claim num="0003">
          <business:ClaimText>
  前記制御部は、前記ショベルの周辺で前記監視対象を検知しているか否か、及び、前記ショベルが動き出さない状態か否かに基づいて前記ショベルの動きの制限を解除する、

  請求項１又は２に記載のショベル。
</business:ClaimText>
        </business:Claim>
        <business:Claim num="0004">
          <business:ClaimText>
  前記ショベルが動き出さない状態が確保されていることは、操作装置が所定時間以上にわたって中立位置になっていること、ゲートロックレバーが下ろされていること、又は、操作装置から操作者の手足が離されていることを含む、

  請求項１乃至３の何れかに記載のショベル。
</business:ClaimText>
        </business:Claim>
        <business:Claim num="0005">
          <business:ClaimText>
  前記ショベルが動き出さない状態が確保されていることという条件は、所定の解除操作が行われた場合に満たされる、

  請求項１乃至４の何れかに記載のショベル。
</business:ClaimText>
        </business:Claim>
        <business:Claim num="0006">
          <business:ClaimText>
  前記所定の解除操作は、急に動き出さないことの確認を促す表示が行われている状態での解除操作、又は、急に動き出さない状態が確保された状態での解除操作、を含む、

  請求項５に記載のショベル。
</business:ClaimText>
        </business:Claim>
        <business:Claim num="0007">
          <business:ClaimText>
  前記ショベルの動きを制限している状態は、操作装置の操作が無効になっている状態、操作装置が反応しない状態、エンジンを停止させた状態、又は、アクチュエータの動きが制限された状態を含む、

  請求項１乃至６の何れかに記載のショベル。
</business:ClaimText>
        </business:Claim>
        <business:Claim num="0008">
          <business:ClaimText>
  前記制御部は、前記ショベルの周辺に存在する前記監視対象が検知されて前記ショベルの状態が前記第２状態となっているときに、前記監視対象の画像が含まれた撮像画像をディスプレイに表示させ、或いは、検知方向に対応する方向から音声で報知する、

  請求項１乃至７の何れかに記載のショベル。
</business:ClaimText>
        </business:Claim>
        <business:Claim num="0009">
          <business:ClaimText>
  前記制御部は、前記ショベルの状態が前記第２状態となっているときに、前記第２状態となっていることを伝える情報を報知し、或いは、前記第２状態を解除する方法を報知する、

  請求項１乃至８の何れかに記載のショベル。
</business:ClaimText>
        </business:Claim>
        <business:Claim num="0010">
          <business:ClaimText>
  前記制御部は、前記ショベルの状態を前記第２状態に切り換えた後で、前記所定の条件が満たされた場合、前記第１状態に戻すまでの待ち時間が存在することを報知し、或いは、所定時間の経過の後に、前記第１状態に戻す、

  請求項１乃至９の何れかに記載のショベル。
</business:ClaimText>
        </business:Claim>
      </business:Claims>
    </business:AmendBody>
  </business:WOAmendedClaims>
</business:PatentDocumentAndRelated>