<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE PatentDocumentAndRelated  SYSTEM '/DTDS/ExternalStandards/ipphdb-entities.dtd' []><business:PatentDocumentAndRelated xmlns:base="http://www.sipo.gov.cn/XMLSchema/base" xmlns:business="http://www.sipo.gov.cn/XMLSchema/business" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:tbl="http://oasis-open.org/specs/soextblx" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.sipo.gov.cn/XMLSchema/business /DTDS/PatentDocument/Elements/OtherElements.xsd" xsdVersion="V2.2.1" file="JP102020000022887JP00020200924470AFULJA20200611JP00X.XML" dateProduced="20200613" status="C" lang="ja" country="JP" docNumber="2020092447" kind="A" datePublication="20200611">
  <business:BibliographicData lang="ja" country="JP">
    <business:PublicationReference dataFormat="original" sequence="1" sourceDB="JP">
      <base:DocumentID>
        <base:WIPOST3Code>JP</base:WIPOST3Code>
        <base:DocNumber>2020092447</base:DocNumber>
        <base:Kind>A</base:Kind>
        <base:Date>20200611</base:Date>
      </base:DocumentID>
    </business:PublicationReference>
    <business:PublicationReference dataFormat="standard" sequence="1">
      <base:DocumentID>
        <base:WIPOST3Code>JP</base:WIPOST3Code>
        <base:DocNumber>2020092447</base:DocNumber>
        <base:Kind>A</base:Kind>
        <base:Date>20200611</base:Date>
      </base:DocumentID>
    </business:PublicationReference>
    <business:PlainLanguageDesignation lang="ja">公開特許公報(A)</business:PlainLanguageDesignation>
    <business:ApplicationReference applType="10" dataFormat="standard" sequence="1">
      <base:DocumentID>
        <base:WIPOST3Code>JP</base:WIPOST3Code>
        <base:DocNumber>102020000022887</base:DocNumber>
        <base:Date>20200213</base:Date>
      </base:DocumentID>
    </business:ApplicationReference>
    <business:ApplicationReference applType="10" dataFormat="original" sequence="1" sourceDB="JP">
      <base:DocumentID>
        <base:WIPOST3Code>JP</base:WIPOST3Code>
        <base:DocNumber>2020022887</base:DocNumber>
        <base:Date>20200213</base:Date>
      </base:DocumentID>
    </business:ApplicationReference>
    <business:ClassificationIPCRDetails>
      <business:ClassificationIPCR sequence="1">
        <business:IPCVersionDate>20060101</business:IPCVersionDate>
        <business:ClassificationLevel>A</business:ClassificationLevel>
        <business:Section>H</business:Section>
        <business:MainClass>04</business:MainClass>
        <business:Subclass>N</business:Subclass>
        <business:MainGroup>7</business:MainGroup>
        <business:Subgroup>18</business:Subgroup>
        <business:SymbolPosition>F</business:SymbolPosition>
        <business:ClassificationValue>I</business:ClassificationValue>
        <base:ActionDate>
          <base:Date>20200515</base:Date>
        </base:ActionDate>
        <business:GeneratingOffice>
          <base:WIPOST3Code>JP</base:WIPOST3Code>
        </business:GeneratingOffice>
        <business:ClassificationStatus>B</business:ClassificationStatus>
        <business:ClassificationDataSource>H</business:ClassificationDataSource>
        <base:Text>H04N   7/18        20060101AFI20200515BHJP        </base:Text>
      </business:ClassificationIPCR>
      <business:ClassificationIPCR sequence="2">
        <business:IPCVersionDate>20060101</business:IPCVersionDate>
        <business:ClassificationLevel>A</business:ClassificationLevel>
        <business:Section>E</business:Section>
        <business:MainClass>02</business:MainClass>
        <business:Subclass>F</business:Subclass>
        <business:MainGroup>9</business:MainGroup>
        <business:Subgroup>26</business:Subgroup>
        <business:SymbolPosition>L</business:SymbolPosition>
        <business:ClassificationValue>I</business:ClassificationValue>
        <base:ActionDate>
          <base:Date>20200515</base:Date>
        </base:ActionDate>
        <business:GeneratingOffice>
          <base:WIPOST3Code>JP</base:WIPOST3Code>
        </business:GeneratingOffice>
        <business:ClassificationStatus>B</business:ClassificationStatus>
        <business:ClassificationDataSource>H</business:ClassificationDataSource>
        <base:Text>E02F   9/26        20060101ALI20200515BHJP        </base:Text>
      </business:ClassificationIPCR>
      <business:ClassificationIPCR sequence="3">
        <business:IPCVersionDate>20170101</business:IPCVersionDate>
        <business:ClassificationLevel>A</business:ClassificationLevel>
        <business:Section>G</business:Section>
        <business:MainClass>06</business:MainClass>
        <business:Subclass>T</business:Subclass>
        <business:MainGroup>7</business:MainGroup>
        <business:Subgroup>00</business:Subgroup>
        <business:SymbolPosition>L</business:SymbolPosition>
        <business:ClassificationValue>I</business:ClassificationValue>
        <base:ActionDate>
          <base:Date>20200515</base:Date>
        </base:ActionDate>
        <business:GeneratingOffice>
          <base:WIPOST3Code>JP</base:WIPOST3Code>
        </business:GeneratingOffice>
        <business:ClassificationStatus>B</business:ClassificationStatus>
        <business:ClassificationDataSource>H</business:ClassificationDataSource>
        <base:Text>G06T   7/00        20170101ALI20200515BHJP        </base:Text>
      </business:ClassificationIPCR>
    </business:ClassificationIPCRDetails>
    <business:JPClassification>
      <business:FI type="main">H04N7/18 J</business:FI>
      <business:FI type="secondary">E02F9/26 B</business:FI>
      <business:FI type="secondary">G06T7/00 660B</business:FI>
      <business:FClass>
        <business:FTerm>2D015HA03</business:FTerm>
      </business:FClass>
      <business:FClass>
        <business:FTerm>2D015HB04</business:FTerm>
      </business:FClass>
      <business:FClass>
        <business:FTerm>2D015HB05</business:FTerm>
      </business:FClass>
      <business:FClass>
        <business:FTerm>5C054CA04</business:FTerm>
      </business:FClass>
      <business:FClass>
        <business:FTerm>5C054CC02</business:FTerm>
      </business:FClass>
      <business:FClass>
        <business:FTerm>5C054EA05</business:FTerm>
      </business:FClass>
      <business:FClass>
        <business:FTerm>5C054FC12</business:FTerm>
      </business:FClass>
      <business:FClass>
        <business:FTerm>5C054FD03</business:FTerm>
      </business:FClass>
      <business:FClass>
        <business:FTerm>5C054FE09</business:FTerm>
      </business:FClass>
      <business:FClass>
        <business:FTerm>5C054FE16</business:FTerm>
      </business:FClass>
      <business:FClass>
        <business:FTerm>5C054FE18</business:FTerm>
      </business:FClass>
      <business:FClass>
        <business:FTerm>5C054HA30</business:FTerm>
      </business:FClass>
      <business:FClass>
        <business:FTerm>5L096BA02</business:FTerm>
      </business:FClass>
      <business:FClass>
        <business:FTerm>5L096BA20</business:FTerm>
      </business:FClass>
      <business:FClass>
        <business:FTerm>5L096CA05</business:FTerm>
      </business:FClass>
      <business:FClass>
        <business:FTerm>5L096FA66</business:FTerm>
      </business:FClass>
      <business:FClass>
        <business:FTerm>5L096JA11</business:FTerm>
      </business:FClass>
      <business:FClass>
        <business:Theme>2D015</business:Theme>
      </business:FClass>
      <business:FClass>
        <business:Theme>5C054</business:Theme>
      </business:FClass>
      <business:FClass>
        <business:Theme>5L096</business:Theme>
      </business:FClass>
    </business:JPClassification>
    <business:InventionTitle lang="ja" dataFormat="original" sourceDB="JP">铲子</business:InventionTitle>
    <business:RelatedDocuments>
      <business:Division>
        <business:DocumentsRelation>
          <business:ParentDocument>
            <base:DocumentID sequence="1" lang="ja">
              <base:DocNumber>2015233976</base:DocNumber>
              <base:Date>20151130</base:Date>
            </base:DocumentID>
          </business:ParentDocument>
          <business:ChildDocument>
            <base:DocumentID>
              <base:Date>00000000</base:Date>
            </base:DocumentID>
          </business:ChildDocument>
        </business:DocumentsRelation>
      </business:Division>
    </business:RelatedDocuments>
    <business:Parties>
      <business:ApplicantDetails>
        <business:Applicant sequence="1" dataFormat="original" sourceDB="JP">
          <base:AddressBook lang="ja">
            <base:Name>住友重機械工業株式会社</base:Name>
            <base:RegisteredNumber>000002107</base:RegisteredNumber>
            <base:Address>
              <base:AddressLine>0</base:AddressLine>
              <base:AddressMailCode>0</base:AddressMailCode>
              <base:PostBox>0</base:PostBox>
              <base:AddressRoom>0</base:AddressRoom>
              <base:AddressFloor>0</base:AddressFloor>
              <base:AddressBuilding>0</base:AddressBuilding>
              <base:Street>0</base:Street>
              <base:AddressCity>0</base:AddressCity>
              <base:County>0</base:County>
              <base:City>0</base:City>
              <base:Province>0</base:Province>
              <base:PostCode>0</base:PostCode>
              <base:WIPOST3Code>JP</base:WIPOST3Code>
              <base:Text>東京都品川区大崎二丁目1番1号</base:Text>
            </base:Address>
          </base:AddressBook>
          <business:OrganizationCode createDate="00000000" creator="00">0000000000</business:OrganizationCode>
        </business:Applicant>
      </business:ApplicantDetails>
      <business:InventorDetails>
        <business:Inventor sequence="1" dataFormat="original" sourceDB="JP">
          <base:AddressBook lang="ja">
            <base:Name>清田  芳永</base:Name>
            <base:Address>
              <base:AddressLine>0</base:AddressLine>
              <base:AddressMailCode>0</base:AddressMailCode>
              <base:PostBox>0</base:PostBox>
              <base:AddressRoom>0</base:AddressRoom>
              <base:AddressFloor>0</base:AddressFloor>
              <base:AddressBuilding>0</base:AddressBuilding>
              <base:Street>0</base:Street>
              <base:AddressCity>0</base:AddressCity>
              <base:County>0</base:County>
              <base:City>0</base:City>
              <base:Province>0</base:Province>
              <base:PostCode>0</base:PostCode>
              <base:WIPOST3Code>JP</base:WIPOST3Code>
              <base:Text>神奈川県横須賀市夏島町19番地  住友重機械工業株式会社  横須賀製造所内</base:Text>
            </base:Address>
          </base:AddressBook>
        </business:Inventor>
        <business:Inventor sequence="2" dataFormat="original" sourceDB="JP">
          <base:AddressBook lang="ja">
            <base:Name>大槻  俊介</base:Name>
            <base:Address>
              <base:AddressLine>0</base:AddressLine>
              <base:AddressMailCode>0</base:AddressMailCode>
              <base:PostBox>0</base:PostBox>
              <base:AddressRoom>0</base:AddressRoom>
              <base:AddressFloor>0</base:AddressFloor>
              <base:AddressBuilding>0</base:AddressBuilding>
              <base:Street>0</base:Street>
              <base:AddressCity>0</base:AddressCity>
              <base:County>0</base:County>
              <base:City>0</base:City>
              <base:Province>0</base:Province>
              <base:PostCode>0</base:PostCode>
              <base:WIPOST3Code>JP</base:WIPOST3Code>
              <base:Text>神奈川県横須賀市夏島町19番地  住友重機械工業株式会社  横須賀製造所内</base:Text>
            </base:Address>
          </base:AddressBook>
        </business:Inventor>
        <business:Inventor sequence="3" dataFormat="original" sourceDB="JP">
          <base:AddressBook lang="ja">
            <base:Name>相澤  晋</base:Name>
            <base:Address>
              <base:AddressLine>0</base:AddressLine>
              <base:AddressMailCode>0</base:AddressMailCode>
              <base:PostBox>0</base:PostBox>
              <base:AddressRoom>0</base:AddressRoom>
              <base:AddressFloor>0</base:AddressFloor>
              <base:AddressBuilding>0</base:AddressBuilding>
              <base:Street>0</base:Street>
              <base:AddressCity>0</base:AddressCity>
              <base:County>0</base:County>
              <base:City>0</base:City>
              <base:Province>0</base:Province>
              <base:PostCode>0</base:PostCode>
              <base:WIPOST3Code>JP</base:WIPOST3Code>
              <base:Text>神奈川県横須賀市夏島町19番地  住友重機械工業株式会社  横須賀製造所内</base:Text>
            </base:Address>
          </base:AddressBook>
        </business:Inventor>
      </business:InventorDetails>
      <business:AgentDetails>
        <business:CustomerNumber>00000</business:CustomerNumber>
        <business:Agent sequence="1" dataFormat="original" sourceDB="JP" repType="agent">
          <base:AddressBook lang="ja">
            <base:Name>伊東  忠重</base:Name>
            <base:RegisteredNumber>100107766</base:RegisteredNumber>
          </base:AddressBook>
        </business:Agent>
        <business:Agent sequence="2" dataFormat="original" sourceDB="JP" repType="agent">
          <base:AddressBook lang="ja">
            <base:Name>伊東  忠彦</base:Name>
            <base:RegisteredNumber>100070150</base:RegisteredNumber>
          </base:AddressBook>
        </business:Agent>
      </business:AgentDetails>
    </business:Parties>
    <business:SpecificBibliographicData>
      <business:OriginalKindCode>A</business:OriginalKindCode>
    </business:SpecificBibliographicData>
    <business:StatisticalInformation>
      <business:ClaimsCount>10</business:ClaimsCount>
      <base:TotalPageCount>29</base:TotalPageCount>
    </business:StatisticalInformation>
  </business:BibliographicData>
  <business:Abstract dataFormat="original" lang="ja" sourceDB="JP">
    <base:Paragraphs>本发明提供一种工作机械用周边监视系统,能够使操作者容易地识别由工作机械检测到的人存在于显示图像内的哪个区域。 周边监视系统100具备检测存在于挖土机周边的人的人检测部34及控制搭载于挖土机的输出装置50的控制部35。 控制部35将使用安装于挖土机的摄像装置40的摄像图像而生成的输出图像显示于显示器,当人物检测部34检测到存在于挖土机周边的人物时输出警报,且以能够区分的方式显示与人物检测部34检测到的人物对应的输出图像上的图像部分。 图2</base:Paragraphs>
    <business:AbstractFigure>
      <base:Figure num="0001">
        <base:Image id="000002" he="49" wi="69" file="2020092447_000002.TIF" imgFormat="TIFF" imgContent="drawing"/>
      </base:Figure>
    </business:AbstractFigure>
  </business:Abstract>
  <business:Description dataFormat="original" sourceDB="JP">
    <business:TechnicalField>
      <base:Paragraphs num="0001">本发明涉及一种监视作业机械的周围的作业机械用周边监视系统。</base:Paragraphs>
    </business:TechnicalField>
    <business:BackgroundArt>
      <base:Paragraphs num="0002">已知有具备检测存在于挖土机周边的物体（人）的传感器的挖土机（参考专利文献1。 。 该挖土机在挖土机的右侧检测到物体（人）时,从设置于驾驶室内的右壁的扬声器输出警报,且将拍摄挖土机的右侧的摄像机的实时取景图像显示于显示器。 并且,当在挖土机的左侧检测到物体（人）时,从设置于驾驶室内的左壁的扬声器输出警报,且将拍摄挖土机的左侧的摄像机的实时取景图像显示于显示器。</base:Paragraphs>
    </business:BackgroundArt>
    <business:CitationList>
      <business:PatentDocumentation>
        <base:Paragraphs num="0003">           <business:ApplicationCitation num="0001">
            <base:Text>特開2014－183500号公報</base:Text>
          </business:ApplicationCitation> </base:Paragraphs>
      </business:PatentDocumentation>
    </business:CitationList>
    <business:InventionSummary>
      <business:TechnicalProblem>
        <base:Paragraphs num="0004">然而,上述挖土机并不将传感器所检测到的物体（人）与显示于显示器的图像内的物体（人）建立对应关系。 因此,观察显示器的操作者有可能无法识别传感器检测到的物体（人）是图像内的哪个物体（人）。</base:Paragraphs>
        <base:Paragraphs num="0005">鉴于上述情况,希望提供一种能够使操作人员容易识别通过工作机械检测到的人存在于显示图像内的哪个区域的工作机械用周边监视系统。</base:Paragraphs>
      </business:TechnicalProblem>
      <business:TechnicalSolution>
        <base:Paragraphs num="0006">本发明的实施例所涉及的工作机械用周边监视系统具备检测存在于所述工作机械的周边的人的人检测部及控制搭载于所述工作机械的输出装置的控制部,所述控制部将使用安装于所述工作机械的摄像装置的摄像图像而生成的输出图像显示于显示器,当所述人检测部检测到存在于所述工作机械的周边的人时输出警报,且以能够区分的方式显示与所述人检测部检测到的人对应的所述输出图像上的图像部分。</base:Paragraphs>
      </business:TechnicalSolution>
      <business:AdvantageousEffects>
        <base:Paragraphs num="0007">通过上述手段,提供一种能够使操作者轻松地识别通过工作机械检测到的人存在于显示图像内的哪个区域的工作机械用周边监视系统。</base:Paragraphs>
      </business:AdvantageousEffects>
    </business:InventionSummary>
    <business:DrawingsDescription>
      <base:Paragraphs num="0008">
        <base:FigureReference num="0001">图0001是搭载本发明的实施例所涉及的周边监视系统的挖土机的侧视图。</base:FigureReference>
        <base:FigureReference num="0002">图0002是表示周边监视系统的结构例的功能框图。</base:FigureReference>
        <base:FigureReference num="0003">图0003是后方相机的拍摄图像的例子。</base:FigureReference>
        <base:FigureReference num="0004">图0004是表示从摄像图像切出识别处理对象图像时使用的几何学的关系的一例的示意图。</base:FigureReference>
        <base:FigureReference num="0005">图0005是挖土机后方的实际空间的俯视图。</base:FigureReference>
        <base:FigureReference num="0006">图0006是表示从拍摄图像生成标准化图像的处理的流程的图。</base:FigureReference>
        <base:FigureReference num="0007">图0007是表示摄像图像、识别处理对象图像区域及标准化图像的关系的图。</base:FigureReference>
        <base:FigureReference num="0008">图0008是表示识别处理对象图像区域与识别处理不适合区域的关系的图。</base:FigureReference>
        <base:FigureReference num="0009">图0009是表示标准化图像的例子的图。</base:FigureReference>
        <base:FigureReference num="0010">图0010是表示从摄像图像切出识别处理对象图像时所使用的几何学关系的另一例的示意图。</base:FigureReference>
        <base:FigureReference num="0011">图0011是表示摄像图像中的特征图像的一例的图。</base:FigureReference>
        <base:FigureReference num="0012">图0012是表示图像提取处理的一例的流程的流程图。</base:FigureReference>
        <base:FigureReference num="0013">图0013是表示周边监视处理的一例的流程的流程图。</base:FigureReference>
        <base:FigureReference num="0014">图0014是表示限制解除处理的一例的流程的流程图。</base:FigureReference>
        <base:FigureReference num="0015">图0015是图示输出图像的示例的图。</base:FigureReference>
        <base:FigureReference num="0016">图0016是表示检测状态与框和区域的显示颜色之间的对应关系的对应表。</base:FigureReference>
        <base:FigureReference num="0017">图0017是作为输出图像的视点转换图像的示例。</base:FigureReference>
        <base:FigureReference num="0018">图0018是包含视点变换图像的输出图像的例子。</base:FigureReference>
      </base:Paragraphs>
    </business:DrawingsDescription>
    <business:EmbodimentsDescription>
      <base:Paragraphs num="0009">图1是作为搭载本发明的实施例所涉及的周边监视系统100的工程机械的挖土机的侧视图。 在挖土机的下部行走体1上经由回转机构2搭载有上部回转体3。 在上部回转体3安装有动臂4。 在动臂4的前端安装有斗杆5,在斗杆5的前端安装有铲斗6。 动臂4、斗杆5及铲斗6构成挖掘附件,通过动臂缸7、斗杆缸8及铲斗缸9分别被液压驱动。 并且,在上部回转体3设置有驾驶室10,且搭载有引擎等动力源。 并且,在上部回转体3的上部安装有摄像装置40。 具体而言,在上部回转体3的后端上部、左端上部、右端上部安装有后方摄像机40B、左侧摄像机40L、右侧摄像机40R。 并且,在驾驶室10内设置有控制器30及输出装置50。</base:Paragraphs>
      <base:Paragraphs num="0010">图2是表示周边监视系统100的结构例的功能框图。 周边监视系统100主要包括控制器30、摄像装置40及输出装置50。</base:Paragraphs>
      <base:Paragraphs num="0011">控制器30为进行挖土机的驱动控制的控制装置。 本实施例中,控制器30由包括CPU及内部存储器的运算处理装置构成,使CPU执行存储于内部存储器的驱动控制用程序来实现各种功能。</base:Paragraphs>
      <base:Paragraphs num="0012">并且,控制器30根据各种装置的输出判定挖土机的周边是否存在人,并根据该判定结果控制各种装置。 具体而言,控制器30接收摄像装置40及输入装置41的输出,并执行分别与提取部31、识别部32、跟踪部33及控制部35对应的软件程序。 而且,根据该执行结果向机械控制装置51输出控制指令而执行挖土机的驱动控制,或者从输出装置50输出各种信息。 另外,控制器30可以是图像处理专用的控制装置。</base:Paragraphs>
      <base:Paragraphs num="0013">摄像装置40为拍摄挖土机的周围的图像的装置,对控制器30输出所拍摄的图像。 在本实施例中,摄像装置40为采用CCD等摄像元件的广角相机,在上部回转体3的上部以光轴朝向斜下方的方式安装。</base:Paragraphs>
      <base:Paragraphs num="0014">输入装置41是接受操作者的输入的装置。 在本实施例中,输入装置41包括操作装置（操作杆、操作踏板等）、门锁杆、设置于操作装置的前端的按钮、附属于车载显示器的按钮、触摸面板等。</base:Paragraphs>
      <base:Paragraphs num="0015">输出装置50是输出各种信息的装置,例如包括显示各种图像信息的车载显示器、声音输出各种声音信息的车载扬声器、警报蜂鸣器、警报灯等。 本实施例中,输出装置50根据来自控制器30的控制指令输出各种信息。</base:Paragraphs>
      <base:Paragraphs num="0016">机械控制装置51为控制挖土机的动作的装置,例如包括控制液压系统中的工作油的流动的控制阀、门锁阀、发动机控制装置等。</base:Paragraphs>
      <base:Paragraphs num="0017">提取部31是从摄像装置40所拍摄的摄像图像中提取识别处理对象图像的功能要件。 具体而言,提取部31进行提取基于局部的亮度梯度或边缘的简易的特征、基于Hough变换等的几何学特征、与基于亮度分割出的区域的面积或纵横比有关的特征等的运算量比较少的图像处理（以下,称为“前级图像识别处理”。 提取识别处理对象图像。 识别处理对象图像为成为后续的图像处理的对象的图像部分（摄像图像的一部分）,包含人候选图像。 人物候选图像是被认为是人物图像的可能性较高的图像部分（摄像图像的一部分）。</base:Paragraphs>
      <base:Paragraphs num="0018">识别部32为识别提取部31所提取的识别处理对象图像中所包含的人物候选图像是否为人物图像的功能要件。 具体而言,识别部32进行使用了以HOG（Histograms of Oriented Gradients：定向梯度直方图）特征量为代表的图像特征量描述和通过机器学习生成的识别器的图像识别处理等运算量比较多的图像处理（以下,称为“后级图像识别处理”。 识别人物候选图像是否为人物图像。 基于提取部31的识别处理对象图像的提取的精度越高,则识别部32将人物候选图像识别为人物图像的比例越高。 另外,当在夜间、恶劣天气时等不适于拍摄的环境下无法获得所希望的品质的摄像图像时等,识别部32可以将所有人候选图像识别为人图像,并将提取部31所提取的识别处理对象图像中的所有人候选图像识别为人。 这是为了防止人的漏检。</base:Paragraphs>
      <base:Paragraphs num="0019">接着,参考图3,对后方摄像机40B所拍摄的挖土机后方的摄像图像中的人物图像的外观进行说明。 另外,图3的2个摄像图像为后方摄像机40B的摄像图像的例子。 并且,图3的虚线圆表示人物图像的存在,而不显示于实际的摄像图像。</base:Paragraphs>
      <base:Paragraphs num="0020">后方摄像机40B为广角摄像机,且安装于从斜上方俯视人的高度。 因此,摄像图像中的人物图像的外观根据从后方摄像机40B观察的人的存在方向而大不相同。 例如,摄像图像中的人物图像越靠近摄像图像的左右端部越倾斜地显示。 这是由广角照相机的广角镜头引起的像倾斜引起的。 并且,越靠近后方摄像机40B则头部显示得越大。 并且,腿部进入挖土机的车体的死角而导致看不见。 这些起因于后方摄像机40B的设置位置。 因此,很难不对摄像图像实施任何加工而通过图像处理来识别该摄像图像中所包含的人物图像。</base:Paragraphs>
      <base:Paragraphs num="0021">因此,本发明的实施例所涉及的周边监视系统100通过对识别处理对象图像进行标准化,促进识别处理对象图像中所包含的人物图像的识别。 另外,“标准化”是指将识别处理对象图像转换为规定尺寸及规定形状的图像。 在本实施例中,在摄像图像中能够采取各种形状的识别处理对象图像通过投影变换而被变换为规定尺寸的长方形图像。 另外,作为投影变换,例如使用8个变量的投影变换矩阵。</base:Paragraphs>
      <base:Paragraphs num="0022">在此,参考图4～图6,周边监视系统100对识别处理对象图像进行标准化的处理（以下,设为“标准化处理”。 以下相同）的一个例子进行说明。 另外,图4是表示提取部31从摄像图像切出识别处理对象图像时使用的几何学关系的一例的示意图。</base:Paragraphs>
      <base:Paragraphs num="0023">图4的框BX是实际空间中的虚拟立体物,在本实施例中,是由8个顶点A～H确定的虚拟长方体。 并且,点Pr是为了参考识别处理对象图像而预先设定的参考点。 在本实施例中,参考点Pr是作为人的假定站立位置而预先设定的点,位于由四个顶点A～D确定的四边形ABCD的中心。 另外,框BX的尺寸基于人的朝向、步幅、身高等来设定。 在本实施例中,四边形ABCD及四边形EFGH为正方形,一边的长度例如为800mm。 另外,长方体的高度例如为1800mm。 即,框BX是宽度800mm×深度800mm×高度1800mm的长方体。</base:Paragraphs>
      <base:Paragraphs num="0024">由4个顶点A、B、G、H确定的四边形ABGH形成与摄像图像中的识别处理对象图像的区域对应的虚拟平面区域TR。 另外,作为虚拟平面区域TR的四边形ABGH相对于作为水平面的虚拟地面倾斜。</base:Paragraphs>
      <base:Paragraphs num="0025">另外,在本实施例中,为了确定参考点Pr与虚拟平面区域TR的关系,采用作为虚拟长方体的框BX。 然而,只要能够将朝向摄像装置40的方向且相对于虚拟地面倾斜的虚拟平面区域TR与任意的参考点Pr建立关联地决定,则也可以采用使用了其他虚拟立体物的关系等其他几何学关系,还可以采用函数、转换表等其他数学关系。</base:Paragraphs>
      <base:Paragraphs num="0026">图5是挖土机后方的实际空间的俯视图,表示使用参考点Pr1、Pr2参考了假想平面区域TR1、TR2时的后方摄像机40B与假想平面区域TR1、TR2的位置关系。 此外,在本实施例中,参考点Pr能够配置于虚拟地面上的虚拟网格的格子点的每一个。 但是,参考点Pr可以不规则地配置于虚拟地面上,也可以等间隔地配置于从后方摄像机40B向虚拟地面的投影点以放射状延伸的线段上。 例如,各线段每隔1度呈放射状延伸,参考点Pr在各线段上以100mm间隔配置。</base:Paragraphs>
      <base:Paragraphs num="0027">如图4和图5所示,四边形ABFE（参照图4。 当使用参考点Pr1参考虚拟平面区域TR1时,确定的盒子BX的第1面配置成与后方摄像机40B正对。 即,连结后方摄像机40B与参考点Pr1的线段在俯视时与和参考点Pr1关联配置的盒子BX的第1面正交。 同样地,当使用参考点Pr2参考虚拟平面区域TR2时,盒BX的第1面也配置成与后方摄像机40B正对。 即,连结后方摄像机40B与参考点Pr2的线段在俯视时与和参考点Pr2相关联地配置的盒子BX的第1面正交。 该关系在参考点Pr配置于任一格子点上的情况下均成立。 即,框BX以其第1面始终与后方摄像机40B正对的方式配置。</base:Paragraphs>
      <base:Paragraphs num="0028">图6是表示从拍摄图像生成标准化图像的处理的流程的图。 具体而言,图6(A)为后方摄像机40B的摄像图像的一例,显现出与实际空间中的参考点Pr相关联地配置的盒子BX。 另外,图6(B)是摄像图像中的识别处理对象图像的区域（以下,设为“识别处理对象图像区域TRg”。 的图,对应于图6(A)的拍摄图像中映出的虚拟平面区域TR。 另外,图6(C)表示将具有识别处理对象图像区域TRg的识别处理对象图像标准化后的标准化图像TRgt。</base:Paragraphs>
      <base:Paragraphs num="0029">如图6(A)所示,在实际空间上与参考点Pr1相关联地配置的框BX确定实际空间中的虚拟平面区域TR的位置,而且,确定与虚拟平面区域TR对应的摄像图像上的识别处理对象图像区域TRg。</base:Paragraphs>
      <base:Paragraphs num="0030">如此,若确定实际空间中的参考点Pr的位置,则实际空间中的虚拟平面区域TR的位置唯一地确定,摄像图像中的识别处理对象图像区域TRg也唯一地确定。 并且,提取部31能够对具有识别处理对象图像区域TRg的识别处理对象图像进行标准化而生成规定尺寸的标准化图像TRgt。 在本实施例中,标准化图像TRgt的尺寸例如为纵64像素×横32像素。</base:Paragraphs>
      <base:Paragraphs num="0031">图7是表示摄像图像、识别处理对象图像区域及标准化图像的关系的图。 具体而言,图7（A1）表示摄像图像中的识别处理对象图像区域TRg3,图7（A2）表示具有识别处理对象图像区域TRg3的识别处理对象图像的标准化图像TRgt3。 另外,图7（B1）表示摄像图像中的识别处理对象图像区域TRg4,图7（B2）表示具有识别处理对象图像区域TRg4的识别处理对象图像的标准化图像TRgt4。 同样地,图7（C1）表示摄像图像中的识别处理对象图像区域TRg5,图7（C2）表示具有识别处理对象图像区域TRg5的识别处理对象图像的标准化图像TRgt5。</base:Paragraphs>
      <base:Paragraphs num="0032">如图7所示,摄像图像中的识别处理对象图像区域TRg5大于摄像图像中的识别处理对象图像区域TRg4。 这是因为与识别处理对象图像区域TRg5对应的虚拟平面区域与后方摄像机40B之间的距离小于与识别处理对象图像区域TRg4对应的虚拟平面区域与后方摄像机40B之间的距离。 同样地,摄像图像中的识别处理对象图像区域TRg4大于摄像图像中的识别处理对象图像区域TRg3。 这是因为与识别处理对象图像区域TRg4对应的虚拟平面区域与后方摄像机40B之间的距离小于与识别处理对象图像区域TRg3对应的虚拟平面区域与后方摄像机40B之间的距离。 即,所对应的虚拟平面区域与后方摄像机40B之间的距离越大,摄像图像中的识别处理对象图像区域越小。 另一方面,标准化图像TRgt3、TRgt4、TRgt5均为相同尺寸的长方形图像。</base:Paragraphs>
      <base:Paragraphs num="0033">如此,提取部31能够将摄像图像中可采取各种形状及尺寸的识别处理对象图像标准化为规定尺寸的长方形图像,并将包含人物图像的人物候选图像标准化。 具体而言,提取部31在标准化图像的规定区域包含估计为人候选图像的头部的图像部分（以下,设为“头部图像部分”。 的规格化距离的幂函数。 并且,在标准化图像的另一规定区域设置有推断为人候选图像的躯干部的图像部分（以下,设为“躯干部图像部分”。 以下,设为“腿部图像部分”,在标准化图像的又一规定区域配置推定为人候选图像的腿部的图像部分（以下,设为“腿部图像部分”。 的规格化距离的幂函数。 并且,提取部31能够在抑制了人候选图像相对于标准化图像的形状的倾斜（像倾斜）的状态下获取标准化图像。</base:Paragraphs>
      <base:Paragraphs num="0034">接着,参考图8,识别处理对象图像区域为对人物图像的识别产生不良影响的不适合识别的图像区域（以下,设为“识别处理不适合区域”。 的情况下的标准化处理进行说明。 识别处理不适合区域为不可能存在人物图像的已知的区域,例如为拍入有挖土机的车体的区域（以下,设为“车体拍入区域”。 从拍摄图像超出的区域（以下,称为“超出区域”。 等。 另外,图8是表示识别处理对象图像区域与识别处理不适合区域的关系的图,与图7（C1）及图7（C2）对应。 另外,图8左图的右下的斜线阴影区域对应于超出区域R1,左下的斜线阴影区域对应于车体映入区域R2。</base:Paragraphs>
      <base:Paragraphs num="0035">在本实施例中,当识别处理对象图像区域TRg5包含超出区域R1及车体映入区域R2的一部分时,提取部31在对这些识别处理不适合区域进行屏蔽处理之后,生成具有识别处理对象图像区域TRg5的识别处理对象图像的标准化图像TRgt5。 另外,提取部31也可以在生成标准化图像TRgt5之后,对标准化图像TRgt5中的与识别处理不适合区域对应的部分进行掩模处理。</base:Paragraphs>
      <base:Paragraphs num="0036">图8右图表示标准化图像TRgt5。 另外,在图8右图中,右下的斜线阴影区域表示与超出区域R1对应的遮蔽区域M1,左下的斜线阴影区域表示与车身映入区域R2的一部分对应的遮蔽区域M2。</base:Paragraphs>
      <base:Paragraphs num="0037">这样,提取部31通过对识别处理不适合区域的图像进行掩模处理,来防止识别处理不适合区域的图像对识别部32的识别处理造成影响。 通过该屏蔽处理,识别部32不会受到识别处理不适合区域的图像的影响,而能够使用标准化图像中的屏蔽区域以外的区域的图像来识别是否为人物图像。 另外,提取部31也可以通过掩模处理以外的其他任意的公知方法,使得识别处理不适合区域的图像不会对识别部32的识别处理造成影响。</base:Paragraphs>
      <base:Paragraphs num="0038">接下来,参照图9,对提取部31生成的标准化图像的特征进行说明。 另外,图9是表示标准化图像的例子的图。 并且,图9所示的14张标准化图像中,越是靠近图的左端的标准化图像,越包含存在于靠近后方摄像机40B的位置的人候选的图像,越是靠近图的右端的标准化图像,越包含存在于远离后方摄像机40B的位置的人候选的图像。</base:Paragraphs>
      <base:Paragraphs num="0039">如图9所示,提取部31能够与实际空间中的虚拟平面区域TR与后方摄像机40B之间的后方水平距离（图5所示的Y轴方向的水平距离）无关地,在任何标准化图像内均以大致相同的比例配置头部图像部分、躯体部图像部分、腿部图像部分等。 因此,提取部31能够降低识别部32执行识别处理时的运算负荷,并且能够提高该识别结果的可靠性。 另外,上述后方水平距离为与实际空间中的虚拟平面区域TR与后方摄像机40B之间的位置关系有关的信息的一例,提取部31对所提取的识别处理对象图像附加该信息。 并且,与上述位置关系相关的信息包括连结与虚拟平面区域TR对应的参考点Pr和后方摄像机40B的线段相对于后方摄像机40B的光轴的俯视角度等。</base:Paragraphs>
      <base:Paragraphs num="0040">通过以上结构,周边监视系统100从与朝向摄像装置40的方向且相对于水平面即虚拟地面倾斜的虚拟平面区域TR对应的识别处理对象图像区域TRg生成标准化图像TRgt。 因此,能够实现考虑了人的高度方向以及进深方向的外观的标准化。 其结果,即使在使用以从斜上方拍摄人的方式安装于工程机械的拍摄装置40的拍摄图像的情况下,也能够更可靠地检测存在于工程机械的周围的人。 尤其,即使在人接近摄像装置40的情况下,也能够从占据摄像图像上的足够大小的区域的识别处理对象图像生成标准化图像,因此能够可靠地检测该人。</base:Paragraphs>
      <base:Paragraphs num="0041">并且,周边监视系统100将虚拟平面区域TR定义为由实际空间中的虚拟长方体即盒子BX的4个顶点A、B、G、H形成的矩形区域。 因此,能够使实际空间中的参考点Pr与虚拟平面区域TR在几何学上对应,进而,能够使实际空间中的虚拟平面区域TR与摄像图像中的识别处理对象图像区域TRg在几何学上对应。</base:Paragraphs>
      <base:Paragraphs num="0042">另外,提取部31对识别处理对象图像区域TRg所包含的识别处理不适合区域的图像进行掩模处理。 因此,识别部32不会受到包括车体映入区域R2的识别处理不适合区域的图像的影响,而能够使用标准化图像中的屏蔽区域以外的区域的图像来识别是否为人物图像。</base:Paragraphs>
      <base:Paragraphs num="0043">并且,提取部31能够按每个参考点Pr提取识别处理对象图像。 并且,识别处理对象图像区域TRg分别经由对应的虚拟平面区域TR而与作为人的假定站立位置而预先设定的参考点Pr中的1个建立关联。 因此,周边监视系统100通过以任意的方法提取人存在的可能性高的参考点Pr,能够提取包含人候选图像的可能性高的识别处理对象图像。 在该情况下,能够防止对包含人物候选图像的可能性较低的识别处理对象图像实施基于运算量较多的图像处理的识别处理,并能够实现人物检测处理的高速化。</base:Paragraphs>
      <base:Paragraphs num="0044">接着,参考图10及图11,对提取部31提取包含人候选图像的可能性高的识别处理对象图像的处理的一例进行说明。 另外,图10是表示提取部31从摄像图像切出识别处理对象图像时使用的几何学关系的一例的示意图,与图4对应。 另外,图11是表示拍摄图像中的特征图像的一例的图。 此外,特征图像是表示人的特征部分的图像,优选是表示实际空间中的距地面的高度难以变化的部分的图像。 因此,特征图像例如包含安全帽的图像、肩的图像、头的图像、安装于人的反射板或标记的图像等。</base:Paragraphs>
      <base:Paragraphs num="0045">特别是,头盔具有如下特征：其形状大致为球体,在其投影像投影到拍摄图像上时,与拍摄方向无关地始终接近圆形。 并且,头盔具有如下特征：表面硬质且具有光泽或半光泽,在其投影像投影到摄像图像上时容易产生局部的高亮度区域和以该区域为中心的放射状的亮度梯度。 因此,安全帽的图像特别适合作为特征图像。 另外,该投影像接近圆形这一特征、容易产生以局部的高亮度区域为中心的放射状的亮度梯度这一特征等可以用于从摄像图像找出安全帽的图像的图像处理。 并且,从摄像图像找出安全帽的图像的图像处理例如包括亮度平滑化处理、高斯平滑化处理、亮度极大点搜索处理、亮度极小点搜索处理等。</base:Paragraphs>
      <base:Paragraphs num="0046">在本实施例中,提取部31通过前级图像识别处理找出摄像图像中的安全帽图像（严格地说能够推断为安全帽的图像）。 这是因为认为在挖土机的周围工作的人佩戴安全帽。 而且,提取部31从所找到的安全帽图像的位置导出关联性最高的参考点Pr。 而且,提取部31提取与该参考点Pr对应的识别处理对象图像。</base:Paragraphs>
      <base:Paragraphs num="0047">具体而言,提取部31利用图10所示的几何学关系,从摄像图像中的安全帽图像的位置导出关联性高的参考点Pr。 此外,图10的几何学的关系在确定实际空间中的虚拟头部位置HP这一点上与图4的几何学的关系不同,但在其他方面相同。</base:Paragraphs>
      <base:Paragraphs num="0048">虚拟头部位置HP表示假定存在于参考点Pr上的人的头部位置,配置于参考点Pr的正上方。 在本实施例中,配置于参考点Pr上的高度1700mm处。 因此,若确定实际空间中的虚拟头部位置HP,则实际空间中的参考点Pr的位置唯一地确定,实际空间中的虚拟平面区域TR的位置也唯一地确定。 并且,摄像图像中的识别处理对象图像区域TRg也唯一地确定。 并且,提取部31能够对具有识别处理对象图像区域TRg的识别处理对象图像进行标准化而生成规定尺寸的标准化图像TRgt。</base:Paragraphs>
      <base:Paragraphs num="0049">相反,若确定实际空间中的参考点Pr的位置,则实际空间中的虚拟头部位置HP唯一地确定,与实际空间中的虚拟头部位置HP对应的摄像图像上的头部图像位置AP也唯一地确定。 因此,头部图像位置AP能够与预先设定的参考点Pr分别建立对应地预先设定。 另外,头部图像位置AP也可以从参考点Pr实时导出。</base:Paragraphs>
      <base:Paragraphs num="0050">因此,提取部31通过前级图像识别处理在后方摄像机40B的摄像图像内搜索安全帽图像。 图11上图表示提取部31找到安全帽图像HRg的状态。 而且,当找出安全帽图像HRg时,提取部31确定其代表位置RP。 另外,代表位置RP为根据安全帽图像HRg的大小、形状等导出的位置。 在本实施例中,代表位置RP为包含安全帽图像HRg的安全帽图像区域的中心像素的位置。 图11下图是图11上图中的由白线划分的矩形图像区域即安全帽图像区域的放大图,表示该安全帽图像区域的中心像素的位置为代表位置RP。</base:Paragraphs>
      <base:Paragraphs num="0051">然后,提取部31例如使用最近邻搜索算法导出位于代表位置RP的最附近的头部图像位置AP。 图11下图表示在代表位置RP的附近预先设定有6个头部图像位置AP1～AP6,其中的头部图像位置AP5为位于代表位置RP的最附近的头部图像位置AP。</base:Paragraphs>
      <base:Paragraphs num="0052">然后,提取部31利用图10所示的几何学关系,从导出的最近邻的头部图像位置AP追溯虚拟头部位置HP、参考点Pr、虚拟平面区域TR,提取对应的识别处理对象图像区域TRg。 然后,提取部31对具有所提取的识别处理对象图像区域TRg的识别处理对象图像进行标准化而生成标准化图像TRgt。</base:Paragraphs>
      <base:Paragraphs num="0053">如此,提取部31通过将作为摄像图像中的人的特征图像的位置的安全帽图像HRg的代表位置RP与预先设定的头部图像位置AP中的1个（头部图像位置AP5）建立对应来提取识别处理对象图像。</base:Paragraphs>
      <base:Paragraphs num="0054">另外,提取部31也可以代替利用图10所示的几何学关系,而利用将头部图像位置AP与参考点Pr、虚拟平面区域TR或识别处理对象图像区域TRg直接对应起来的参考表,提取与头部图像位置AP对应的识别处理对象图像。</base:Paragraphs>
      <base:Paragraphs num="0055">并且,提取部31也可以使用爬山法、Mean-shift法等最近邻搜索算法以外的其他公知的算法从代表位置RP导出参考点Pr。 例如,在使用登山法的情况下,提取部31导出位于代表位置RP附近的多个头部图像位置AP,并将代表位置RP和与这些多个头部图像位置AP分别对应的参考点Pr建立关联。 此时,提取部31以代表位置RP与头部图像位置AP越近则权重越大的方式对参考点Pr进行加权。 而且,在多个参考点Pr的权重的分布上爬山,从具有最接近权重的极大点的权重的参考点Pr提取识别处理对象图像区域TRg。</base:Paragraphs>
      <base:Paragraphs num="0056">接着,参考图12,对控制器30的提取部31提取识别处理对象图像的处理（以下,设为“图像提取处理”。 以下相同）的一个例子进行说明。 另外,图12是表示图像提取处理的一例的流程的流程图。</base:Paragraphs>
      <base:Paragraphs num="0057">首先,提取部31在摄像图像内搜索安全帽图像（步骤ST1）。 在本实施例中,提取部31通过前级图像识别处理对后方摄像机40B的摄像图像进行光栅扫描而找出安全帽图像。</base:Paragraphs>
      <base:Paragraphs num="0058">当在摄像图像中找到了安全帽图像HRg时（步骤ST1的“是”）,提取部31获取安全帽图像HRg的代表位置RP（步骤ST2）。</base:Paragraphs>
      <base:Paragraphs num="0059">然后,提取部31获取位于所获取的代表位置RP的最近附近的头部图像位置AP（步骤ST3）。</base:Paragraphs>
      <base:Paragraphs num="0060">然后,提取部31提取与所取得的头部图像位置AP对应的识别处理对象图像（步骤ST4）。 在本实施例中,提取部31利用图10所示的几何学关系,追踪拍摄图像中的头部图像位置AP、实际空间中的虚拟头部位置HP、作为实际空间中的人的假定站立位置的参考点Pr、以及实际空间中的虚拟平面区域TR的对应关系来提取识别处理对象图像。</base:Paragraphs>
      <base:Paragraphs num="0061">另外,提取部31在摄像图像中未找出安全帽图像HRg时（步骤ST1的“否”）,不提取识别处理对象图像,而将处理转移到步骤ST5。</base:Paragraphs>
      <base:Paragraphs num="0062">之后,提取部31判定是否遍及摄像图像的整体搜索了安全帽图像（步骤ST5）。</base:Paragraphs>
      <base:Paragraphs num="0063">在判定为尚未搜索拍摄图像的整体的情况下（步骤ST5的“否”）,提取部31对拍摄图像的其他区域执行步骤ST1～步骤ST4的处理。</base:Paragraphs>
      <base:Paragraphs num="0064">另一方面,当判定为已完成遍及摄像图像整体的安全帽图像的搜索时（步骤ST5的“是”）,提取部31结束本次图像提取处理。</base:Paragraphs>
      <base:Paragraphs num="0065">如此,提取部31首先找出安全帽图像HRg,并从所找出的安全帽图像HRg的代表位置RP经过头部图像位置AP、虚拟头部位置HP、参考点（假定站立位置）Pr、虚拟平面区域TR而确定识别处理对象图像区域TRg。 并且,通过提取具有所确定的识别处理对象图像区域TRg的识别处理对象图像并进行标准化,能够生成规定尺寸的标准化图像TRgt。</base:Paragraphs>
      <base:Paragraphs num="0066">通过以上结构,周边监视系统100的提取部31找出摄像图像中的作为特征图像的安全帽图像,并将该安全帽图像的代表位置RP与作为规定图像位置的头部图像位置AP中的一个建立对应,由此提取识别处理对象图像。 因此,能够以简单的系统结构缩小成为后级图像识别处理的对象的图像部分。</base:Paragraphs>
      <base:Paragraphs num="0067">另外,提取部31可以首先从摄像图像找出安全帽图像HRg,导出与该安全帽图像HRg的代表位置RP对应的头部图像位置AP的1个,并提取与该头部图像位置AP的1个对应的识别处理对象图像。 或者,提取部31可以首先获取头部图像位置AP中的1个,当在包含与该头部图像位置AP中的1个对应的特征图像的位置的规定区域即安全帽图像区域内存在安全帽图像时,提取与该头部图像位置AP中的1个对应的识别处理对象图像。</base:Paragraphs>
      <base:Paragraphs num="0068">并且,提取部31可以利用如图10所示的规定的几何学关系,从摄像图像中的安全帽图像的代表位置RP提取识别处理对象图像。 在该情况下,规定的几何学关系表示摄像图像中的识别处理对象图像区域TRg、与识别处理对象图像区域TRg对应的实际空间中的虚拟平面区域TR、与虚拟平面区域TR对应的实际空间中的参考点Pr（人的假定站立位置）、与参考点Pr对应的虚拟头部位置HP（与人的假定站立位置对应的人的特征部分在实际空间中的位置即虚拟特征位置）、与虚拟头部位置HP对应的摄像图像中的头部图像位置AP（与虚拟特征位置对应的摄像图像中的规定图像位置）的几何学关系。</base:Paragraphs>
      <base:Paragraphs num="0069">在此,再次参考图2,继续对控制器30的其他功能要件进行说明。</base:Paragraphs>
      <base:Paragraphs num="0070">跟踪部33是跟踪识别部32每隔规定时间输出的识别结果并输出最终的人检测结果的功能要件。 在本实施例中,当连续的规定次数的与同一人有关的识别结果满足规定条件时,跟踪部33判定为所对应的人候选图像为人图像。 即,判定为在对应的三维位置（实际位置）存在人。 是否为同一人基于其实际位置来判定。 具体而言,跟踪部33根据在基于识别部32的第1次识别处理中识别为人物图像的图像中映现的人的实际位置（参考点PrI）,导出该人在规定时间内能够到达的范围。 能够到达的范围根据挖土机的最大回转速度、挖土机的最大行走速度、人的最大移动速度等而设定。 而且,若在第2次识别处理中识别为人物图像的图像中映现的人的实际位置（参考点PrII）在该范围内,则判定为同一人。 对于第三次以后的识别处理也是同样的。 而且,例如当在连续的6次识别结果中的4次中识别为同一人的人物图像时,跟踪部33判定为在所对应的三维位置存在人。 并且,即使在第1次识别处理中识别为人物图像的情况下,当在之后的连续的3次识别处理中未识别出同一人物的人物图像时,也判定为在所对应的三维位置上不存在人。</base:Paragraphs>
      <base:Paragraphs num="0071">如此,提取部31、识别部32及跟踪部33的组合构成根据摄像装置40的摄像图像检测在挖土机的周边是否存在人的人检测部34。</base:Paragraphs>
      <base:Paragraphs num="0072">通过该结构,人检测部34能够抑制误报（尽管不存在人但判定为存在人的情况）、失报（尽管存在人但判定为不存在人的情况）等的发生。</base:Paragraphs>
      <base:Paragraphs num="0073">并且,人物检测部34根据识别为人物图像的图像中映现的人的实际位置的推移,能够判断人是靠近挖土机还是远离挖土机。 而且,当该人的实际位置距挖土机的距离小于规定值时,人检测部34可以向控制部35输出控制指令而输出警报。 在该情况下,人检测部34也可以根据挖土机的动作信息（例如回转速度、回转方向、行走速度、行走方向等）调整规定值。</base:Paragraphs>
      <base:Paragraphs num="0074">并且,人检测部34可以判别并识别至少两个阶段的人检测状态与人非检测状态。 例如,可以将满足与距离相关的条件及与可靠性相关的条件中的至少一个的状态判断为第1人物检测状态（警戒状态）,将满足双方的状态判断为第2人物检测状态（警报状态）。 与距离有关的条件例如包括被识别为人物图像的图像中映现的人的实际位置距挖土机的距离小于规定值。 与可靠性相关的条件例如包括在连续的6次识别结果中的4次中识别为同一人的人物图像。 在第1人物检测状态（警戒状态）下,输出准确度较低但响应较快的作为预备性警报的第1警报。 第一警报例如是小音量的蜂鸣声,在两个条件均不满足的情况下自动停止。 在第2人物检测状态（警报状态）下,输出准确度高但响应慢的作为正式警报的第2警报。 第二警报例如是大音量的旋律音,即使不满足至少一方的条件也不会自动停止,该停止需要操作者的操作。</base:Paragraphs>
      <base:Paragraphs num="0075">控制部35是控制各种装置的功能要素。 在本实施例中,控制部35根据经由输入装置41的操作者的输入来控制各种装置。 例如,根据通过触摸面板输入的图像切换指令来切换显示于车载显示器的画面的显示图像。 显示图像包含后方摄像机40B的实时取景图像、右侧摄像机40R的实时取景图像、左侧摄像机40L的实时取景图像、视点转换图像等。 视点转换图像例如为由多个摄像机的拍摄图像合成的鸟瞰图像（从位于挖土机的正上方的假想视点观察的图像）。</base:Paragraphs>
      <base:Paragraphs num="0076">并且,控制部35根据构成人检测部34的跟踪部33的最终的人检测结果来控制各种装置。 例如,根据跟踪部33的最终的人物检测结果向机械控制装置51输出控制指令而在第1状态与第2状态之间切换挖土机的状态。 第1状态包括挖土机的动作的限制被解除的状态、警报的输出被停止的状态等。 第2状态包括限制或停止挖土机的动作的状态、输出警报的状态等。 在本实施例中,当根据跟踪部33的最终的人检测结果判定为在挖土机周边的规定范围内存在人时,控制部35向机械控制装置51输出控制指令而将挖土机的状态从第1状态切换为第2状态。 例如,使挖土机的动作停止。 在该情况下,操作者的操作被设为无效。 操作者的操作的无效化例如通过使操作装置成为不反应的状态来实现。 具体而言,向门锁阀输出控制指令而将操作装置从液压系统断开,由此强制性地创造无操作状态而使挖土机的动作停止。 或者,也可以向发动机控制装置输出控制指令而使发动机停止。 或者,也可以向对流入液压致动器的工作油的流量进行控制的控制阀输出控制指令而使控制阀的开口面积、开口面积变化速度等变化,由此限制液压致动器的动作。 在该情况下,最大回转速度、最大行驶速度等降低。 另外,也可以通过关闭控制阀来使液压致动器的动作停止。</base:Paragraphs>
      <base:Paragraphs num="0077">并且,当在将挖土机的状态设为第2状态之后满足规定的解除条件时,控制部35将挖土机的状态恢复为第1状态。 即,在限制或停止挖土机的动作之后满足规定的解除条件时,解除该限制或停止。 规定的解除条件例如为“判定为在挖土机周边的规定范围内不存在人”（以下,设为“第1解除条件”。 [数学式1] 并且,规定的解除条件例如为“确保挖土机不动作的状态”（以下,设为“第2解除条件”。 以及 并且,规定的解除条件为“通过操作人员确认到挖土机周边无人”（以下,设为“第3解除条件”。 以下相同）。 另外,在本实施例中,使用标志来管理挖土机的动作是否被限制或停止、是否分别满足第1解除条件、第2解除条件、第3解除条件。</base:Paragraphs>
      <base:Paragraphs num="0078">第1解除条件例如包括“根据构成人检测部34的跟踪部33的最终的人检测结果,控制部35判定为在挖土机周边的规定范围内不存在人”。</base:Paragraphs>
      <base:Paragraphs num="0079">第2解除条件例如包括“所有操作装置在规定时间以上处于中立位置”、“门锁杆被放下（操作装置成为无效）”、“操作者的手脚从所有操作装置离开”、“进行了规定的解除操作”等。 例如,控制部35基于来自各操作装置的指令的有无、检测各操作装置的操作量的传感器的输出值等来检测“全部的操作装置处于中立位置”。 “经过规定时间以上”这样的条件具有防止仅瞬间成为中立位置就满足第二解除条件的效果。 控制部35例如基于对驾驶室内进行拍摄的摄像机的拍摄图像、安装于操作装置（例如操作杆的把手）的静电传感器的输出等来检测“操作者的手脚从操作装置离开”。 “进行了规定的解除操作”是指例如在车载显示器的画面上显示“是否确保了挖土机不移动的状态？” 这样的消息的状态下按下了确认按钮（例如喇叭按钮或显示在同一画面上的软件按钮）的情况下,控制部35进行检测。 控制部35例如可以在进行了对位于驾驶座的杆、按钮、面板等的操作输入等由操作人员进行的解除操作时判断为“确保了挖土机不动作的状态”。</base:Paragraphs>
      <base:Paragraphs num="0080">第3解除条件例如为在车载显示器的画面上显示“确认到挖土机周边没有人吗？” 这样的消息的状态下按下确认按钮的情况下,满足。 另外,也可以省略第3解除条件。</base:Paragraphs>
      <base:Paragraphs num="0081">当规定的解除条件中包含第3解除条件时,若满足第1解除条件和第2解除条件,则挖土机成为能够解除限制状态。 能够解除限制状态是指只要操作人员确认挖土机周边没有人就能够解除限制的状态。</base:Paragraphs>
      <base:Paragraphs num="0082">分别满足第1解除条件、第2解除条件及第3解除条件的顺序没有限制。 例如,即使在以第3解除条件、第2解除条件、第1解除条件的顺序满足条件的情况下,控制部35也解除挖土机的动作的限制或停止。</base:Paragraphs>
      <base:Paragraphs num="0083">另外,控制部35也可以在满足规定的解除条件后经过了规定的等待时间时解除该限制或停止。 这是为了避免因突然的解除而使操作者慌张。</base:Paragraphs>
      <base:Paragraphs num="0084">并且,当限制或停止挖土机的动作时,控制部35可以向作为输出装置50的车载显示器输出控制指令,并显示包含成为其原因的人物图像的摄像图像。 例如,当仅在左侧方摄像机40L的摄像图像中包含人物图像时,可以单独显示左侧方摄像机40L的直通图像。 或者,当左侧方摄像机40L的摄像图像和后方摄像机40B的摄像图像分别包含人物图像时,可以并排同时显示2个摄像机各自的实时取景图像,也可以显示包含2个摄像机的摄像图像的1个合成图像（例如视点转换图像）。 另外,也可以显示表示限制中或停止中的图像、解除方法的指导等。 并且,也可以强调显示与识别为人物图像的人物候选图像对应的图像部分。 例如,也可以以规定颜色显示识别处理对象图像区域TRg的轮廓线。 另外,在设定了满足规定的解除条件后的等待时间的情况下,也可以在满足规定的解除条件时向操作者通知存在等待时间。 例如,也可以在显示了存在等待时间的意思的基础上,显示等待时间的倒计时。 另外,在等待时间中输出警报的情况下,也可以随着等待时间的经过而逐渐减小该警报的音量。</base:Paragraphs>
      <base:Paragraphs num="0085">并且,当限制或停止挖土机的动作时,控制部35可以向作为输出装置50的车载扬声器输出控制指令,并在成为其原因的人所存在的一侧输出警报。 在该情况下,车载扬声器例如由设置于驾驶室内的右壁的右侧方扬声器、设置于左壁的左侧方扬声器、以及设置于后壁的后方扬声器构成。 而且,当仅在左侧方摄像机40L的摄像图像中包含人物图像时,控制部35仅从左侧方扬声器输出警报。 或者,控制部35也可以使用包括多个扬声器的环绕系统来定位声音。</base:Paragraphs>
      <base:Paragraphs num="0086">并且,当人物检测部34将人物候选图像识别为人物图像时,控制部35也可以不限制或停止挖土机的动作而仅输出警报。 在该情况下,如上所述,控制部35也可以将满足与距离相关的条件及与可靠性相关的条件中的至少一个的状态判断为第1人物检测状态（警戒状态）,将满足双方的状态判断为第2人物检测状态（警报状态）。 而且,与限制或停止挖土机的动作的情况同样地,当满足规定的解除条件时,控制部35可以停止第2人物检测状态（警报状态）下的警报。 这是因为,与能够自动停止的第1人物检测状态（警戒状态）下的警报不同,第2人物检测状态（警报状态）下的警报的停止需要操作人员的操作。</base:Paragraphs>
      <base:Paragraphs num="0087">接着,参考图13,对控制器30的控制部35监视挖土机的周边的处理（以下,设为“周边监视处理”。 以下相同）的一个例子进行说明。 图13是表示周边监视处理的一例的流程的流程图,控制器30以规定的控制周期反复执行该周边监视处理。</base:Paragraphs>
      <base:Paragraphs num="0088">首先,控制部35判定挖土机周边是否存在人（步骤ST11）。 在本实施例中,控制部35根据跟踪部33的最终的人检测结果判定在挖土机周边是否存在人。</base:Paragraphs>
      <base:Paragraphs num="0089">之后,当判定为挖土机周边存在人时（步骤ST11的“是”）,控制部35限制或停止挖土机的动作（步骤ST12）。 在本实施例中,控制部35例如在判断为当前的人物检测状态为第2人物检测状态（警报状态）时,判定为在挖土机周边存在人而停止挖土机的动作。</base:Paragraphs>
      <base:Paragraphs num="0090">此时,控制部35向作为输出装置50的车载扬声器输出控制指令而使第二警报输出。 并且,向作为输出装置50的车载显示器输出控制指令而显示包含成为限制或停止的原因的人物图像的摄像图像。</base:Paragraphs>
      <base:Paragraphs num="0091">当判定为挖土机周边不存在人时（步骤ST11的“否”）,控制部35判定挖土机的动作是否已被限制或停止（步骤S13）。 在本实施例中,控制部35参考所对应的标志的值来判定挖土机的动作是否已被限制或停止。</base:Paragraphs>
      <base:Paragraphs num="0092">当判定为挖土机的动作已被限制或停止时（步骤ST13的“是”）,控制部35执行用于解除该限制或停止的处理（以下,设为“限制解除处理”。 （步骤ST14）。</base:Paragraphs>
      <base:Paragraphs num="0093">当判定为挖土机的动作尚未被限制或停止时（步骤ST13的“否”）,控制部35不执行限制解除处理,而结束本次挖土机周边监视处理。</base:Paragraphs>
      <base:Paragraphs num="0094">接着,参考图14,对控制器30的控制部35解除挖土机的动作的限制或停止的处理进行说明。 图14是表示限制解除处理的一例的流程的流程图。</base:Paragraphs>
      <base:Paragraphs num="0095">首先,控制部35判定是否满足第1解除条件（步骤ST21）。 在本实施例中,控制部35判定在挖土机周边的规定范围内是否存在人。 具体而言,判定当前的人物检测状态是否脱离了第2人物检测状态（警报状态）。 也可以判定是否脱离了第1人物检测状态（警戒状态）及第2人物检测状态（警报状态）。</base:Paragraphs>
      <base:Paragraphs num="0096">在判定为满足第1解除条件的情况下（步骤ST21的是）,控制部35判定是否满足第2解除条件（步骤ST22）。 在本实施例中,控制部35判定是否确保了挖土机不动作的状态。 具体而言,判定门锁杆是否下降（操作装置是否无效）。</base:Paragraphs>
      <base:Paragraphs num="0097">在判定为满足第2解除条件的情况下（步骤ST22的是）,控制部35判定是否满足第3解除条件（步骤ST23）。 在本实施例中,控制部35判定是否由操作人员确认到挖土机周边无人。 具体而言,在车载显示器的画面显示“确认到挖土机周边没有人吗？” 这样的消息的状态下是否按下了确认按钮。</base:Paragraphs>
      <base:Paragraphs num="0098">当判定为满足第3解除条件时（步骤ST23的“是”）,控制部35解除挖土机的动作的限制或停止（步骤ST24）。</base:Paragraphs>
      <base:Paragraphs num="0099">此时,控制部35向作为输出装置50的车载扬声器输出控制指令而使第2警报的输出停止。 并且,向作为输出装置50的车载显示器输出控制指令而停止包含成为限制或停止的原因的人物图像的摄像图像的显示。 例如,再次显示在输出第二警报之前显示的直通图像。 并且,控制部35也可以显示传递已解除挖土机的动作的限制或停止的消息。</base:Paragraphs>
      <base:Paragraphs num="0100">另外,控制部35在判定为不满足第1解除条件时（步骤ST21的“否”）、判定为不满足第2解除条件时（步骤ST22的“否”）、判定为不满足第3解除条件时（步骤ST23的“否”）,不解除挖土机的动作的限制或停止,而结束本次限制解除处理。</base:Paragraphs>
      <base:Paragraphs num="0101">通过以上结构,当判定为在挖土机周边存在人时,控制器30能够限制或停止挖土机的动作。</base:Paragraphs>
      <base:Paragraphs num="0102">并且,控制器30在限制或停止挖土机的动作之后判定为挖土机周边不存在人的情况下,仅在判定为确保了挖土机不开始动作的状态时,能够解除该限制或停止。 并且,控制器30仅在判定为确保了挖土机不开始工作的状态且判定为通过操作人员确认到挖土机周边无人时,能够解除该限制或停止。 因此,控制器30能够防止解除该限制或停止时挖土机意外地开始动作。</base:Paragraphs>
      <base:Paragraphs num="0103">接下来,参照图15,对在周边监视处理的执行中显示于车载显示器的输出图像的一个例子进行说明。 图15是根据后方摄像机40B的摄像图像生成的输出图像的例子。 图15(A)表示在挖土机周边的规定范围内没有人时的输出图像的例子,图15(B)表示第1人物检测状态下的输出图像的例子,图15(C)表示第2人物检测状态下的输出图像的例子。</base:Paragraphs>
      <base:Paragraphs num="0104">具体而言,图15的输出图像包含摄像机图像部分G1及指示器部分G2。 摄像机图像部分G1为显示根据1个或多个摄像机的摄像图像而生成的图像的部分。 指示器部分G2为显示挖土机周边的多个区域各自的人物检测状态/人物非检测状态的部分。 在摄像机图像部分G1中,重叠显示于摄像机图像上的线段L1表示距挖土机的距离为规定的第1距离（例如5米）。 并且,重叠显示于摄像机图像上的线段L2表示距挖土机的距离为规定的第2距离（例如2.5米）。 在指示器部分G2中,描绘于挖土机图标CG1的周围的部分圆的外周线L1g表示距挖土机的距离为规定的第1距离（例如5米）,并与摄像机图像部分G1的线段L1对应。 并且,描绘于挖土机图标CG1的周围的部分矩形的外周线L2g表示距挖土机的距离为规定的第2距离（例如2.5米）,与摄像机图像部分G1的线段L2对应。</base:Paragraphs>
      <base:Paragraphs num="0105">部分圆被分割为6个区域A1～A6,部分矩形被分割为3个区域B1～B3。</base:Paragraphs>
      <base:Paragraphs num="0106">在图15(A)所示的状态下,控制器30检测存在于挖土机的右后方的人。 然而,由于该人的实际位置为第1距离以上,因此控制器30不强调显示该人的图像,也不输出第1警报。 但是,控制器30可以将所对应的识别处理对象图像区域TRg的轮廓线显示为白色框等强调显示该人的图像,也可以输出第1警报。 另外,也可以与是否已经检测到人无关地显示“周边监视处理执行中”等消息。 这是为了使操作者能够识别周边监视处理正在执行中。</base:Paragraphs>
      <base:Paragraphs num="0107">在图15(B)所示的第1人物检测状态下,控制器30检测存在于挖土机的右后方的第1距离以内且第2距离以远的人。 因此,控制器30强调显示该人的图像且输出第1警报。 具体而言,控制器30在相机图像部分G1中,将所对应的识别处理对象图像区域TRg的轮廓线作为黄色框F1来显示。 另外,在指示器部分G2中,以黄色显示与该人的实际位置对应的区域A4。 但是,也可以省略黄色框的显示。 并且,也可以显示传达处于第1人物检测状态（警戒状态）的消息。</base:Paragraphs>
      <base:Paragraphs num="0108">在图15(C)所示的第2人物检测状态下,控制器30检测存在于挖土机的右后方的第2距离以内的人。 因此,控制器30强调显示该人的图像且输出第2警报。 具体而言,控制器30在相机图像部分G1中将所对应的识别处理对象图像区域TRg的轮廓线显示为红色框F2。 另外,在指示器部分G2中,用红色显示与该人的实际位置对应的区域B2。 并且,控制器30在限制挖土机的动作的基础上,闪烁显示传递为第2人物检测状态（警报状态）的消息“挖土机动作限制中”。 但是,可以省略传达为第2人物检测状态（警报状态）的消息的显示。</base:Paragraphs>
      <base:Paragraphs num="0109">并且,图15(A)～图15(C)中,在画面的左侧显示摄像机图像部分G1,在画面的右侧显示指示器部分G2,但也可以在画面的右侧显示摄像机图像部分G1,在画面的左侧显示指示器部分G2。 并且,也可以在上下分割的画面的一方显示摄像机图像部分G1,在另一方显示指示器部分G2。 另外,也可以省略指示部分G2的显示。</base:Paragraphs>
      <base:Paragraphs num="0110">另外,区域A1～A6各自的扩展角度为45度,区域B1～B3各自的扩展角度为90度。 该扩展角度的差异基于第1人物检测状态（警戒状态）与第2人物检测状态（警报状态）的性质的差异。 具体而言,第1人物检测状态（警戒状态）为输出准确度低但响应快的预备性警报的状态,距离挖土机较远的地方的较宽的空间范围成为监视范围。 因此,若增大区域A1～A6的扩展角度,则与各个区域对应的监视范围与其显示范围一起变大,导致难以知晓成为第1警报的原因的人的实际位置。 这是因为无论在较宽的监视范围的何处都成为相同的显示结果。 另一方面,第2人物检测状态（警报状态）为输出准确度高但响应慢的正式警报的状态,距挖土机较近的地方的较窄的空间范围成为监视范围。 因此,若减小区域B1～B3的扩展角度,则与各个区域对应的监视范围与其显示范围一起变小,难以知晓成为第二警报的原因的人处于哪个方向。 这是因为显示范围小而难以看到。 因此,优选如图15的(A)～图15的(C)所示,区域A1～A6各自的扩展角度设定为比区域B1～B3各自的扩展角度小。</base:Paragraphs>
      <base:Paragraphs num="0111">并且,在图15(A)～图15(C)中,对显示有后方摄像机40B的实时取景图像时在后方摄像机40B的摄像图像中检测到人物图像的情况进行说明。 然而,上述说明也同样适用于显示有后方摄像机40B的实时取景图像时在左侧方摄像机40L及右侧方摄像机40R中的至少一方的摄像图像中检测到人物图像的情况。 该情况下,显示于摄像机图像部分G1的输出图像可以从后方摄像机40B的实时取景图像自动切换为其他摄像机的实时取景图像或从多个摄像机的摄像图像合成的视点转换图像。 例如,当显示有后方摄像机40B的实时取景图像时,在左侧方摄像机40L的摄像图像中检测到人物图像时,控制器30可以将显示于摄像机图像部分G1的输出图像切换为左侧方摄像机40L的实时取景图像。</base:Paragraphs>
      <base:Paragraphs num="0112">接下来,将参照图16描述检测状态与框和区域的显示颜色之间的关系。 图16是示出检测状态与框和区域的显示颜色之间的对应关系的对应表。</base:Paragraphs>
      <base:Paragraphs num="0113">对应表的第1行表示当检测状态既不是第1人物检测状态（警戒状态）也不是第2人物检测状态（警报状态）时,不显示识别处理对象图像区域的轮廓线,且不对指示器部分G2的任一区域进行着色。</base:Paragraphs>
      <base:Paragraphs num="0114">第2行表示当检测状态为警戒状态时,与成为带来警戒状态的原因的人物图像对应的识别处理对象图像区域的轮廓线作为黄色框而显示,且区域A1～A6中的任一个以黄色显示。</base:Paragraphs>
      <base:Paragraphs num="0115">第3行表示当检测状态为警报状态时,与成为带来警报状态的原因的人物图像对应的识别处理对象图像区域的轮廓线作为红色框而显示,且区域B1～B3中的任一个以红色显示。</base:Paragraphs>
      <base:Paragraphs num="0116">第4行表示,当检测状态为警戒状态且为警报状态时,以黄色框显示与成为引起警戒状态的原因的人物图像对应的轮廓线,且以红色框显示与成为引起警报状态的原因的人物图像对应的轮廓线。 并且,表示区域A1～A6中与成为引起警戒状态的原因的人物图像对应的区域以黄色显示,区域B1～B3中与成为引起警报状态的原因的人物图像对应的区域以红色显示。</base:Paragraphs>
      <base:Paragraphs num="0117">通过以上结构,控制器30在判定为挖土机周边存在人时输出警报且强调显示该人的图像部分。 因此,操作者能够在画面上确认成为警报的原因的人。 另外,操作者在发生了误报的情况下也能够在画面上确认成为该误报的原因的是什么。</base:Paragraphs>
      <base:Paragraphs num="0118">并且,当成为第1人物检测状态（警戒状态）时,控制器30首次在摄像机图像部分G1显示作为人物检测标记的框图像,且改变指示器部分G2所对应的区域的颜色。 因此,能够防止连与识别为人物图像但其可靠性还较低的人物候选图像对应的框图像也被显示而导致显示图像复杂化。 另外,在上述实施例中,作为人物检测标记而显示框图像,但也可以采用反转显示图像等其他强调图像作为人物检测标记。</base:Paragraphs>
      <base:Paragraphs num="0119">并且,以能够区分的方式强调显示成为带来第1人物检测状态（警戒状态）的原因的人的图像和成为带来第2人物检测状态（警报状态）的原因的人的图像。 并且,使摄像机图像部分G1中的框图像的颜色与指示器部分G2中的区域的颜色对应。 因此,操作者能够在画面上确认成为第二警报的原因的人。 并且,在上述实施例中,控制器30根据检测状态使摄像机图像部分G1中的框图像的颜色及指示器部分G2中的区域的颜色不同。 但是,控制器30也可以根据检测状态使闪烁/点亮状态、透射率等颜色以外的属性不同。</base:Paragraphs>
      <base:Paragraphs num="0120">接下来,参照图17,对在周边监视处理的执行中显示于车载显示器的输出图像的另一例进行说明。 图17是根据后方摄像机40B、左侧摄像机40L及右侧摄像机40R各自的摄像图像而生成的作为输出图像的视点转换图像的例子。 图17表示第1人物检测状态和第2人物检测状态并存时的输出图像的例子。 图17的输出图像包含与图15的摄像机图像部分G1对应的视点变换图像部分G3。 与图15的指示器部分G2对应的部分被整合为视点转换图像部分G3。 具体而言,图15的挖土机图标CG1与图17的挖土机图标CG2对应,图15的区域A1～A6与图17的区域C1～C6对应。 另外,图15的区域B1对应于图17的区域C1和C2的组合,图15的区域B2对应于图17的区域C3和C4的组合,图15的区域B3对应于图17的区域C5和C6的组合。 重叠显示于视点转换图像上的线段L3表示距挖土机的距离为规定的第3距离（例如2.5米）。</base:Paragraphs>
      <base:Paragraphs num="0121">在图17所示的检测状态下,控制器30检测存在于挖土机的左侧方的第1距离（例如5米）以内且第3距离以上的人（成为导致第1人物检测状态的原因的人）。 并且,检测存在于挖土机的后方的第3距离以内的人（成为导致第2人物检测状态的原因的人）。 因此,控制器30强调显示这些人的图像,输出第2警报,且限制挖土机的动作。 具体而言,控制器30在与成为带来第1人物检测状态的原因的人对应的参考点Pr的位置显示作为人检测标记的黄色圆MA1,且以黄色显示与该位置对应的区域C2。 并且,在与成为带来第2人物检测状态的原因的人对应的参考点Pr的位置显示作为人检测标记的红色圆MA2,且以红色显示与该位置对应的区域C3及C4的组合。 并且,控制器30也可以在限制挖土机的动作的基础上,闪烁显示传递为第2人物检测状态（警报状态）的消息“挖土机动作限制中”。 并且,也可以省略黄色圆MA1的显示。 这是为了容易观察画面。</base:Paragraphs>
      <base:Paragraphs num="0122">接着,参照图18,对在周边监视处理的执行中显示于车载显示器的输出图像的又一例进行说明。 图18是包含根据后方摄像机40B、左侧摄像机40L及右侧摄像机40R各自的摄像图像生成的视点转换图像的输出图像的例子。 图18与图17的情况相同地表示第1人物检测状态和第2人物检测状态并存时的输出图像的例子。 图18的输出图像包含指示器部分G2和视点变换图像部分G3。 描绘于挖土机图标CG1的周围的部分矩形的外周线L2g表示距挖土机的距离为规定的第3距离（例如2.5米）,与视点转换图像部分G3的线段L3对应。</base:Paragraphs>
      <base:Paragraphs num="0123">在图18所示的检测状态下,控制器30检测存在于挖土机的左侧方的第1距离（例如5米）以内且第3距离以上的人（成为导致第1人物检测状态的原因的人）。 并且,检测存在于挖土机的后方的第3距离以内的人（成为导致第2人物检测状态的原因的人）。 因此,控制器30强调显示这些人的图像,输出第2警报,且限制挖土机的动作。 具体而言,控制器30在与成为带来第1人物检测状态的原因的人对应的参考点Pr的位置显示作为人检测标记的黄色圆MA1,且以黄色显示与该位置对应的指示器部分G2的区域A2。 并且,在与成为带来第2人物检测状态的原因的人对应的参考点Pr的位置显示作为人检测标记的红色圆MA2,且以红色显示与该位置对应的指示器部分G2的区域B2。 并且,控制器30在限制挖土机的动作的基础上,闪烁显示传递为第2人物检测状态（警报状态）的消息“挖土机动作限制中”。 另外,也可以省略黄色圆MA1的显示。 这是为了容易观察画面。</base:Paragraphs>
      <base:Paragraphs num="0124">通过以上结构,控制器30能够实现与显示图15的输出图像时相同的效果。</base:Paragraphs>
      <base:Paragraphs num="0125">如此,当判定为挖土机周边存在人时,控制器30限制或停止挖土机的动作且显示该人的图像。 而且,在限制或停止挖土机的动作之后判定为挖土机周边不存在人的情况下,仅在判定为确保了挖土机不开始动作的状态时,判定为能够解除该限制或停止。 然后,在经过了规定的等待时间时,实际解除该限制或停止。 因此,能够更适当地解除根据人的检测而执行的挖土机的动作限制。</base:Paragraphs>
      <base:Paragraphs num="0126">并且,当限制或停止挖土机的动作时,控制器30能够从成为其原因的人所存在的一侧向操作人员输出警报。 因此,能够在操作者观察车载显示器的画面之前,使操作者识别人存在的方向。 操作者通过在根据听到警报的方向而在听觉上识别人存在的方向之后观察车载显示器的画面,能够在视觉上确认人存在于识别出的方向。 如此,控制器30通过警报与显示的协作将人所存在的方向通知给操作人员,因此能够在短时间内使操作人员识别挖土机周边的状况。</base:Paragraphs>
      <base:Paragraphs num="0127">这是因为,即使在通过警报识别出检测到人的情况下,在不知道该人的存在方向时,操作者也需要首先观察画面整体来找出该人存在于哪个方向。 另一方面,这是因为,当在观察画面之前已知该人的存在方向时,操作者仅通过观察画面的一部分（与该存在方向对应的部分）就能够在视觉上确认该人的存在。</base:Paragraphs>
      <base:Paragraphs num="0128">以上,对本发明的优选实施例进行了详细说明,但本发明不限于上述实施例,能够在不脱离本发明的范围的情况下对上述实施例施加各种变形及置换。</base:Paragraphs>
      <base:Paragraphs num="0129">例如,在上述实施例中,设想使用安装于挖土机的上部回转体3上的摄像装置40的摄像图像来检测人的情况,但本发明并不限定于该结构。 也能够应用于使用在移动式起重机、固定式起重机、起重磁铁机、叉车等其他作业机械的主体部安装的摄像装置的摄像图像的结构。</base:Paragraphs>
      <base:Paragraphs num="0130">并且,在上述实施例中,使用3个摄像机来拍摄挖土机的死角区域,但也可以使用1个、2个或4个以上的摄像机来拍摄挖土机的死角区域。</base:Paragraphs>
      <base:Paragraphs num="0131">并且,在上述实施例中,使用摄像装置40的摄像图像来进行人检测,但也可以使用超声波传感器、激光雷达、热电传感器、毫米波雷达等的输出来进行人检测。</base:Paragraphs>
      <base:Paragraphs num="0132">并且,上述实施例中,对多个摄像图像的每一个单独适用人物检测处理,但也可以对由多个摄像图像生成的一个合成图像适用人物检测处理。</base:Paragraphs>
    </business:EmbodimentsDescription>
    <business:ReferenceSignsList>
      <base:Paragraphs num="0133">1…下部行走体,2…回转机构,3…上部回转体,4…动臂,5…斗杆,6…铲斗,7…动臂缸,8…斗杆缸,9…铲斗缸,10…驾驶室,30…控制器,31…抽出部,32…识别部,33…追踪部,34…人检测部,35…控制部,40…摄像装置,40B…后方摄像机,40L…左侧方摄像机,40R…右侧方摄像机,41…输入装置,50…输出装置,51…机械控制装置,100…周边监视系统,AP, AP1～AP6···头部图像位置BX···框G1···照相机图像部分G2···指示器部分G3···视点变换图像部分HD···头部HP···假想头部位置HRg···安全帽图像M1、M2···遮蔽区域Pr、Pr1、Pr2、Pr10～Pr12···参照点R1···超出区域R2···车体映入区域RP···代表位置TR、TR1、TR2、TR10～TR12···假想平面区域TRg、TRg3、TRg4、TRg5···识别处理对象图像区域TRgt、TRgt3、TRgt4、TRgt5···标准化图像</base:Paragraphs>
    </business:ReferenceSignsList>
  </business:Description>
  <business:Drawings lang="ja" sourceDB="JP">
    <base:Figure num="0001">
      <base:Image id="000003" he="59" wi="81" file="2020092447_000003.TIF" imgContent="drawing" imgFormat="TIFF"/>
    </base:Figure>
    <base:Figure num="0002">
      <base:Image id="000004" he="55" wi="77" file="2020092447_000004.TIF" imgContent="drawing" imgFormat="TIFF"/>
    </base:Figure>
    <base:Figure num="0003">
      <base:Image id="000005" he="109" wi="85" file="2020092447_000005.TIF" imgContent="drawing" imgFormat="TIFF"/>
    </base:Figure>
    <base:Figure num="0004">
      <base:Image id="000006" he="47" wi="70" file="2020092447_000006.TIF" imgContent="drawing" imgFormat="TIFF"/>
    </base:Figure>
    <base:Figure num="0005">
      <base:Image id="000007" he="64" wi="70" file="2020092447_000007.TIF" imgContent="drawing" imgFormat="TIFF"/>
    </base:Figure>
    <base:Figure num="0006">
      <base:Image id="000008" he="104" wi="85" file="2020092447_000008.TIF" imgContent="drawing" imgFormat="TIFF"/>
    </base:Figure>
    <base:Figure num="0007">
      <base:Image id="000009" he="106" wi="85" file="2020092447_000009.TIF" imgContent="drawing" imgFormat="TIFF"/>
    </base:Figure>
    <base:Figure num="0008">
      <base:Image id="000010" he="95" wi="85" file="2020092447_000010.TIF" imgContent="drawing" imgFormat="TIFF"/>
    </base:Figure>
    <base:Figure num="0009">
      <base:Image id="000011" he="116" wi="85" file="2020092447_000011.TIF" imgContent="drawing" imgFormat="TIFF"/>
    </base:Figure>
    <base:Figure num="0010">
      <base:Image id="000012" he="47" wi="70" file="2020092447_000012.TIF" imgContent="drawing" imgFormat="TIFF"/>
    </base:Figure>
    <base:Figure num="0011">
      <base:Image id="000013" he="75" wi="85" file="2020092447_000013.TIF" imgContent="drawing" imgFormat="TIFF"/>
    </base:Figure>
    <base:Figure num="0012">
      <base:Image id="000014" he="87" wi="70" file="2020092447_000014.TIF" imgContent="drawing" imgFormat="TIFF"/>
    </base:Figure>
    <base:Figure num="0013">
      <base:Image id="000015" he="54" wi="73" file="2020092447_000015.TIF" imgContent="drawing" imgFormat="TIFF"/>
    </base:Figure>
    <base:Figure num="0014">
      <base:Image id="000016" he="77" wi="70" file="2020092447_000016.TIF" imgContent="drawing" imgFormat="TIFF"/>
    </base:Figure>
    <base:Figure num="0015">
      <base:Image id="000017" he="111" wi="85" file="2020092447_000017.TIF" imgContent="drawing" imgFormat="TIFF"/>
    </base:Figure>
    <base:Figure num="0016">
      <base:Image id="000018" he="32" wi="70" file="2020092447_000018.TIF" imgContent="drawing" imgFormat="TIFF"/>
    </base:Figure>
    <base:Figure num="0017">
      <base:Image id="000019" he="66" wi="85" file="2020092447_000019.TIF" imgContent="drawing" imgFormat="TIFF"/>
    </base:Figure>
    <base:Figure num="0018">
      <base:Image id="000020" he="49" wi="85" file="2020092447_000020.TIF" imgContent="drawing" imgFormat="TIFF"/>
    </base:Figure>
  </business:Drawings>
  <business:Claims lang="ja" dataFormat="original" sourceDB="JP">
    <business:Claim num="0001">
      <business:ClaimText>以及控制部,其控制搭载于所述作业机械的输出装置,所述控制部将使用安装于所述作业机械的摄像装置的摄像图像而生成的输出图像显示于显示器,在所述人检测部检测到存在于所述作业机械的周边的人的情况下输出警报,且以能够区分的方式显示与所述人检测部检测到的人对应的所述输出图像上的图像部分。</business:ClaimText>
    </business:Claim>
    <business:Claim num="0002">
      <business:ClaimText>根据权利要求1所述的工作机械用周边监视系统,其中,所述人员检测部判别并识别至少两个阶段的人员检测状态和人员非检测状态,所述至少两个阶段的人员检测状态包括满足与距所述工作机械的距离相关的条件及与人员检测结果的可靠性相关的条件中的至少一个条件的第1人员检测状态和满足这两个条件的第2人员检测状态,所述控制部以能够区分的方式显示与带来所述第1人员检测状态的人对应的所述输出图像上的图像部分和与带来所述第2人员检测状态的人对应的所述输出图像上的图像部分。</business:ClaimText>
    </business:Claim>
    <business:Claim num="0003">
      <business:ClaimText>根据权利要求2所述的工作机械用周边监视系统,其中,所述控制部使通过所述人检测部识别出所述第1人检测状态时输出的警报的内容与通过所述人检测部识别出所述第2人检测状态时输出的警报的内容不同。</business:ClaimText>
    </business:Claim>
    <business:Claim num="0004">
      <business:ClaimText>根据权利要求2或3所述的工作机械用周边监视系统,其中,所述输出图像包含表示所述工作机械的周边的多个区域各自的人物检测状态/人物非检测状态的指示器部分,所述控制部以能够以不同的颜色区分的方式显示所述第1人物检测状态的区域、所述第2人物检测状态的区域及所述人物非检测状态的区域。</business:ClaimText>
    </business:Claim>
    <business:Claim num="0005">
      <business:ClaimText>根据权利要求1至4中任一项所述的作业机械用周边监视系统,其中,所述输出图像包括使用多个所述摄像装置各自的摄像图像合成的视点转换图像。</business:ClaimText>
    </business:Claim>
  </business:Claims>
  <business:WOAmendedClaims id="woamendedclaims000001" lang="ja">
    <business:AmendBody lang="ja">
      <business:Description lang="ja" dataFormat="original" sourceDB="JP" correction="Y">
        <base:Paragraphs num="0001">本发明涉及一种挖土机。</base:Paragraphs>
        <base:Paragraphs num="0004">然而,专利文献1并未提及传感器检测到物体（人）等监视对象时的挖土机的状态的变化。</base:Paragraphs>
        <base:Paragraphs num="0005">鉴于上述情况,希望提供一种能够根据监视对象的检测适当地改变状态的挖土机。</base:Paragraphs>
        <base:Paragraphs num="0006">本发明的实施例所涉及的挖土机具备： 行驶体； 回转体,其以能够回转的方式搭载于所述行驶体； 作业附属装置,其设置于所述回转体； 以及控制部,根据所述检测部的检测结果,将所述挖土机的状态切换为第1状态或第2状态,所述第1状态包括所述挖土机的操作有效的状态或未输出警报的状态,所述第2状态包括所述挖土机的操作无效的状态或输出警报的状态,在将所述挖土机的状态切换为所述第2状态之后满足规定的条件时,所述控制部将所述挖土机的状态恢复为所述第1状态,所述规定的条件为确保了所述规定范围内的所述监视对象的未检测和所述挖土机不动作的状态。</base:Paragraphs>
        <base:Paragraphs num="0007">通过上述方法,提供一种能够根据监视对象的检测适当地改变状态的挖土机。</base:Paragraphs>
      </business:Description>
      <business:Claims lang="ja" dataFormat="original" sourceDB="JP" correction="Y">
        <business:Claim num="0001">
          <business:ClaimText>行驶体； 回转体,其以能够回转的方式搭载于所述行驶体； 作业附属装置,其设置于所述回转体； 以及控制部,根据所述检测部的检测结果,将所述挖土机的状态切换为第1状态或第2状态,所述第1状态包括所述挖土机的操作有效的状态或未输出警报的状态,所述第2状态包括所述挖土机的操作无效的状态或输出警报的状态,在将所述挖土机的状态切换为所述第2状态之后满足规定的条件时,所述控制部将所述挖土机的状态恢复为所述第1状态,所述规定的条件为确保了所述规定范围内的所述监视对象的未检测和所述挖土机不动作的状态。</business:ClaimText>
        </business:Claim>
        <business:Claim num="0002">
          <business:ClaimText>行驶体； 回转体,其以能够回转的方式搭载于所述行驶体； 作业附属装置,其设置于所述回转体； 以及控制部,根据所述检测部的检测结果,将所述挖土机的状态切换为第1状态或第2状态,所述第1状态包括所述挖土机的动作的限制被解除的状态或未输出警报的状态,所述第2状态包括所述挖土机的动作被限制的状态或输出警报的状态,在将所述挖土机的状态切换为所述第2状态之后满足规定的条件时,所述控制部将所述挖土机的状态恢复为所述第1状态,所述规定的条件为未检测到所述规定范围内的所述监视对象和所述挖土机处于停止状态；</business:ClaimText>
        </business:Claim>
        <business:Claim num="0003">
          <business:ClaimText>根据权利要求1或2所述的挖土机,其中,所述控制部根据在所述挖土机的周边是否检测到所述监视对象及所述挖土机是否处于不开始动作的状态来解除所述挖土机的动作的限制。</business:ClaimText>
        </business:Claim>
        <business:Claim num="0004">
          <business:ClaimText>根据权利要求1至3中任一项所述的挖土机,其中,确保所述挖土机不动作的状态包括操作装置在规定时间以上处于中立位置、门锁杆下降或操作人员的手脚从操作装置离开。</business:ClaimText>
        </business:Claim>
        <business:Claim num="0005">
          <business:ClaimText>根据权利要求1至4中任一项所述的挖土机,其中,确保了所述挖土机不动作的状态这一条件在进行了规定的解除操作时得到满足。</business:ClaimText>
        </business:Claim>
        <business:Claim num="0006">
          <business:ClaimText>根据权利要求5所述的挖土机,其中,所述规定的解除操作包括进行提示确认不突然移动的显示的状态下的解除操作或确保了不突然移动的状态的状态下的解除操作。</business:ClaimText>
        </business:Claim>
        <business:Claim num="0007">
          <business:ClaimText>根据权利要求1至6中任一项所述的挖土机,其中,限制所述挖土机的动作的状态包括操作装置的操作无效的状态、操作装置不反应的状态、使引擎停止的状态或致动器的动作受到限制的状态。</business:ClaimText>
        </business:Claim>
        <business:Claim num="0008">
          <business:ClaimText>根据权利要求1至7中任一项所述的挖土机,其中,当检测到存在于所述挖土机的周边的所述监视对象且所述挖土机的状态成为所述第2状态时,所述控制部将包含所述监视对象的图像的摄像图像显示于显示器,或者从与检测方向对应的方向以语音进行通知。</business:ClaimText>
        </business:Claim>
        <business:Claim num="0009">
          <business:ClaimText>根据权利要求1至8中任一项所述的挖土机,其中,所述控制部在所述挖土机的状态成为所述第2状态时,通知传递成为所述第2状态的信息,或者通知解除所述第2状态的方法。</business:ClaimText>
        </business:Claim>
        <business:Claim num="0010">
          <business:ClaimText>根据权利要求1至9中任一项所述的挖土机,其中,当在将所述挖土机的状态切换为所述第2状态之后满足所述规定的条件时,所述控制部通知存在返回到所述第1状态为止的等待时间,或者在经过规定时间之后返回到所述第1状态。</business:ClaimText>
        </business:Claim>
      </business:Claims>
    </business:AmendBody>
  </business:WOAmendedClaims>
</business:PatentDocumentAndRelated>